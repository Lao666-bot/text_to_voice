# tts_driver.pyï¼ˆç§»é™¤æ‡’åŠ è½½ç‰ˆæœ¬ï¼‰
import os
import asyncio
import queue
import threading
import abc
import numpy as np
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
import time
import wave

os.environ["GENIE_DATA_DIR"] = r"C:\Users\k\Agent\Genie-TTS\GenieData"

# ===================== 1. å¯¼å…¥æµå¼æ¥å£è§„èŒƒ =====================
@dataclass
class AudioData:
    pcm_data: bytes
    sample_rate: int = 16000
    channels: int = 1
    is_finish: bool = False  # æ ‡è®°æ˜¯å¦æ˜¯æœ€åä¸€ä¸ªéŸ³é¢‘åˆ†ç‰‡
    bit_depth: int = 16      # ä½æ·±

@dataclass
class TextData:
    text: str
    is_finish: bool = True

ChatHistory = List[Dict[str, str]]

class BaseModule(abc.ABC):
    @abc.abstractmethod
    def process(self, input_data) -> Any:
        pass

    @abc.abstractmethod
    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        pass

# ===================== 2. å¯¼å…¥ Genie TTS æ ¸å¿ƒå‡½æ•° =====================
from genie_tts import (
    load_character,
    load_predefined_character,
    set_reference_audio,
    tts,
    tts_async,  # çœŸæ­£çš„æµå¼æ¥å£
    unload_character,
    clear_reference_audio_cache,
    stop,
    wait_for_playback_done
)

# ===================== 3. é…ç½®é¡¹ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰ =====================
LOCAL_MODEL_DIR = r"C:\Users\k\Agent\Genie-TTS\CharacterModels\v2ProPlus\feibi\tts_models"
LOCAL_CHAR_NAME = "feibi"
LOCAL_CHAR_LANG = "Chinese"
REFERENCE_AUDIO_PATH = r"C:\Users\k\Agent\Genie-TTS\CharacterModels\v2ProPlus\feibi\prompt_wav\zh_vo_Main_Linaxita_2_1_10_26.wav"
REFERENCE_AUDIO_TEXT = "åœ¨æ­¤ä¹‹å‰,è¯·æ‚¨åŠ¡å¿…ç»§ç»­äº«å—é›¨å­£æ‹‰å¤çº³çš„æ—¶å…‰"
SAVE_DIR = "./tts_output"

# ===================== 4. Genie TTS æµå¼æ¨¡å—å®ç°ï¼ˆç§»é™¤æ‡’åŠ è½½ï¼‰ =====================
class GenieTTSModule(BaseModule):
    def __init__(self):
        """åˆå§‹åŒ–æ—¶ç«‹å³åŠ è½½æ¨¡å‹ï¼ˆç§»é™¤æ‡’åŠ è½½ï¼‰"""
        print("ğŸ”„ TTSæ¨¡å—åˆå§‹åŒ–ä¸­...")
        
        try:
            # 1. åŠ è½½TTSæ¨¡å‹
            print(f"ğŸ”„ åŠ è½½TTSæ¨¡å‹: {LOCAL_CHAR_NAME}")
            load_character(
                character_name=LOCAL_CHAR_NAME,
                onnx_model_dir=LOCAL_MODEL_DIR,
                language=LOCAL_CHAR_LANG
            )
            print(f"âœ… TTSæ¨¡å‹ {LOCAL_CHAR_NAME} åŠ è½½æˆåŠŸ")
            
            # 2. è®¾ç½®å‚è€ƒéŸ³é¢‘
            print(f"ğŸ”„ è®¾ç½®å‚è€ƒéŸ³é¢‘: {REFERENCE_AUDIO_PATH}")
            set_reference_audio(
                character_name=LOCAL_CHAR_NAME,
                audio_path=REFERENCE_AUDIO_PATH,
                audio_text=REFERENCE_AUDIO_TEXT,
                language=LOCAL_CHAR_LANG
            )
            print(f"âœ… å‚è€ƒéŸ³é¢‘è®¾ç½®æˆåŠŸ")
            
            # 3. æ£€æµ‹éŸ³é¢‘æ ¼å¼
            self._detect_audio_format()
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(SAVE_DIR, exist_ok=True)
            
            print("âœ… TTSæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ TTSæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _detect_audio_format(self):
        """æ£€æµ‹TTSéŸ³é¢‘æ ¼å¼"""
        try:
            # ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
            test_text = "æµ‹è¯•éŸ³é¢‘æ ¼å¼"
            test_path = os.path.join(SAVE_DIR, "format_test.wav")
            
            print(f"ğŸ”„ æ£€æµ‹éŸ³é¢‘æ ¼å¼ï¼Œç”Ÿæˆæµ‹è¯•éŸ³é¢‘...")
            tts(
                character_name=LOCAL_CHAR_NAME,
                text=test_text,
                play=False,
                split_sentence=True,
                save_path=test_path
            )
            
            # åˆ†æWAVæ–‡ä»¶æ ¼å¼
            with wave.open(test_path, 'rb') as wf:
                self.sample_rate = wf.getframerate()
                self.channels = wf.getnchannels()
                self.sample_width = wf.getsampwidth()
                self.bit_depth = self.sample_width * 8
                
                print(f"ğŸ“Š TTSéŸ³é¢‘æ ¼å¼æ£€æµ‹ç»“æœï¼š")
                print(f"   é‡‡æ ·ç‡={self.sample_rate}Hz")
                print(f"   å£°é“={self.channels}")
                print(f"   ä½æ·±={self.bit_depth}bit")
                print(f"   æ ·æœ¬å®½åº¦={self.sample_width}å­—èŠ‚")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            try:
                os.remove(test_path)
            except:
                pass
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ ¼å¼æ£€æµ‹å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼
            print("âš ï¸  ä½¿ç”¨é»˜è®¤éŸ³é¢‘æ ¼å¼: 16000Hz/16bit/å•å£°é“")
            self.sample_rate = 16000
            self.channels = 1
            self.bit_depth = 16
            self.sample_width = 2

    def process(self, input_data: TextData) -> AudioData:
        """
        æ‰¹é‡å¤„ç†ï¼ˆéæµå¼ï¼‰ï¼šè¾“å…¥TextDataï¼Œè¾“å‡ºAudioData
        """
        # 1. ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        timestamp = int(time.time())
        save_path = os.path.join(SAVE_DIR, f"{LOCAL_CHAR_NAME}_{timestamp}.wav")
        
        ##print(f"ğŸ”„ æ‰¹é‡å¤„ç†TTS: {input_data.text[:50]}...")
        tts(
            character_name=LOCAL_CHAR_NAME,
            text=input_data.text,
            play=False,
            split_sentence=True,
            save_path=save_path
        )
        
        # 2. è¯»å–éŸ³é¢‘æ–‡ä»¶ä¸ºPCMæ•°æ®
        with open(save_path, "rb") as f:
            pcm_data = f.read()
        
        ##print(f"âœ… æ‰¹é‡TTSå®Œæˆï¼ŒéŸ³é¢‘å¤§å°: {len(pcm_data)} å­—èŠ‚")
        
        # 3. è¿”å›AudioDataæ ¼å¼
        return AudioData(
            pcm_data=pcm_data,
            sample_rate=self.sample_rate,
            channels=self.channels,
            bit_depth=self.bit_depth,
            is_finish=True
        )

    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        """å®æ—¶æµå¼å¤„ç†ï¼šæ¯æ”¶åˆ°ä¸€ä¸ªå¥å­å°±ç«‹å³åˆæˆï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        print("ğŸ”„ å¯åŠ¨å®æ—¶TTSæµå¼å¤„ç†...")
        
        sentence_count = 0
        
        while True:
            try:
                # è·å–æ–‡æœ¬åˆ†ç‰‡ï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼‰
                try:
                    text_data = input_queue.get(timeout=1.0)
                except queue.Empty:
                    continue
                
                # å¦‚æœæ˜¯ç»“æŸæ ‡è®°
                if text_data.is_finish and not text_data.text:
                    output_queue.put(AudioData(
                        pcm_data=b"",
                        sample_rate=self.sample_rate,
                        channels=self.channels,
                        bit_depth=self.bit_depth,
                        is_finish=True
                    ))
                    ##print(f"âœ… TTSæµå¼å¤„ç†å®Œæˆï¼Œå…±åˆæˆ{sentence_count}ä¸ªå¥å­")
                    break
                
                # å¤„ç†å½“å‰æ–‡æœ¬
                text = text_data.text.strip()
                if not text:
                    continue
                
                sentence_count += 1
                ##print(f"ğŸµ TTSå¼€å§‹åˆæˆå¥å­ #{sentence_count}: {text[:50]}...")
                
                # ä½¿ç”¨åŒæ­¥æ–¹æ³•åˆæˆå½“å‰å¥å­
                start_time = time.time()
                
                try:
                    # ä¸ºæ¯ä¸ªå¥å­ç”Ÿæˆä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    timestamp = int(time.time())
                    save_path = os.path.join(SAVE_DIR, f"sentence_{timestamp}_{sentence_count}.wav")
                    
                    # åˆæˆå•ä¸ªå¥å­
                    tts(
                        character_name=LOCAL_CHAR_NAME,
                        text=text,
                        play=False,
                        split_sentence=False,  # å·²ç»æ˜¯å®Œæ•´å¥å­ï¼Œä¸éœ€è¦å†åˆ†å‰²
                        save_path=save_path
                    )
                    
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    with open(save_path, "rb") as f:
                        pcm_data = f.read()
                        
                    pcm_data = self._process_audio_start(pcm_data)
                    
                    elapsed = time.time() - start_time
                    
                    # å‘é€éŸ³é¢‘æ•°æ®
                    output_queue.put(AudioData(
                        pcm_data=pcm_data,
                        sample_rate=self.sample_rate,
                        channels=self.channels,
                        bit_depth=self.bit_depth,
                        is_finish=False
                    ))
                    
                    ##print(f"âœ… TTSå¥å­ #{sentence_count} åˆæˆå®Œæˆï¼Œå¤§å°: {len(pcm_data)} å­—èŠ‚ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.remove(save_path)
                    except:
                        pass
                    
                except Exception as e:
                    print(f"âŒ TTSåˆæˆå¥å­ #{sentence_count} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                
            except Exception as e:
                print(f"âŒ TTSæµå¼å¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                break
    #======================å»é™¤å¼€å¤´çš„æ°”æ³¡éŸ³=====================
    def _process_audio_start(self, pcm_data: bytes) -> bytes:
        """
        å¤„ç†éŸ³é¢‘å¼€å¤´çš„æ±½æ³¡éŸ³
        ç§»é™¤å¼€å¤´çš„é™éŸ³/å™ªå£°æ®µ
        """
        import numpy as np
        
        # å°†å­—èŠ‚è½¬æ¢ä¸ºnumpyæ•°ç»„
        dtype = np.int16 if self.bit_depth == 16 else np.int32
        samples = np.frombuffer(pcm_data, dtype=dtype)
        
        # è®¡ç®—éŸ³é¢‘çš„RMSèƒ½é‡
        window_size = 100  # 10msçª—å£ï¼ˆ16000Hzé‡‡æ ·ç‡ï¼‰
        num_windows = len(samples) // window_size
        
        # å¯»æ‰¾ç¬¬ä¸€ä¸ªéé™éŸ³çª—å£
        start_index = 0
        silence_threshold = 500  # è°ƒæ•´è¿™ä¸ªé˜ˆå€¼
        
        for i in range(min(10, num_windows)):  # åªæ£€æŸ¥å‰10ä¸ªçª—å£ï¼ˆ100msï¼‰
            window = samples[i * window_size:(i + 1) * window_size]
            rms = np.sqrt(np.mean(window.astype(np.float64) ** 2))
            
            if rms > silence_threshold:
                # æ‰¾åˆ°è¯­éŸ³å¼€å§‹ï¼Œç¨å¾®æå‰ä¸€ç‚¹ï¼ˆä½†ä¸è¶…è¿‡å‰ä¸€ä¸ªçª—å£ï¼‰
                start_index = max(0, (i - 1) * window_size)
                print(f"  æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹äºç¬¬{i}ä¸ªçª—å£ï¼ŒRMS={rms:.1f}")
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´å®½æ¾çš„æ¡ä»¶
        if start_index == 0 and len(samples) > 2000:
            # è®¡ç®—æ•´ä¸ªå¼€å¤´çš„RMS
            first_500 = samples[:2000]
            rms_500 = np.sqrt(np.mean(first_500.astype(np.float64) ** 2))
            
            if rms_500 < 100:  # éå¸¸ä½çš„èƒ½é‡ï¼Œå¯èƒ½æ˜¯æ±½æ³¡éŸ³
                # ç›´æ¥è·³è¿‡å‰50msï¼ˆ800ä¸ªæ ·æœ¬ï¼Œ16kHzï¼‰
                start_index = min(800, len(samples) // 2)
                print(f"  ä½èƒ½é‡å¼€å¤´ï¼Œè·³è¿‡å‰{start_index}ä¸ªæ ·æœ¬")
        
        # åº”ç”¨æ·¡å…¥æ•ˆæœï¼Œå‡å°‘çªå˜
        if start_index > 0:
            # åˆ›å»ºä¸€ä¸ªæ·¡å…¥çª—å£ï¼ˆ20msï¼‰
            fade_in_length = min(320, start_index)  # 320 samples = 20ms @ 16kHz
            
            # å¤åˆ¶åŸå§‹éŸ³é¢‘
            processed_samples = samples[start_index:].copy()
            
            # æ·»åŠ æ·¡å…¥æ•ˆæœ
            if fade_in_length > 0 and len(processed_samples) > fade_in_length:
                # åˆ›å»ºæ·¡å…¥æ›²çº¿ï¼ˆçº¿æ€§ï¼‰
                fade_in = np.linspace(0, 1, fade_in_length)
                processed_samples[:fade_in_length] = (processed_samples[:fade_in_length] * fade_in).astype(dtype)
            
            # è½¬æ¢å›å­—èŠ‚
            return processed_samples.tobytes()
        else:
            # æ²¡æœ‰æ‰¾åˆ°æ±½æ³¡éŸ³ï¼Œè¿”å›åŸå§‹æ•°æ®
            return pcm_data
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            print("ğŸ§¹ æ¸…ç†TTSæ¨¡å—èµ„æº...")
            unload_character(character_name=LOCAL_CHAR_NAME)
            clear_reference_audio_cache()
            print("âœ… TTSæ¨¡å—èµ„æºå·²æ¸…ç†")
        except:
            pass


# ===================== 5. æµ‹è¯•ä»£ç  =====================
if __name__ == "__main__":
    # æµ‹è¯•TTSæ¨¡å—
    print("ğŸ§ª æµ‹è¯•TTSæ¨¡å—...")
    
    try:
        # åˆ›å»ºTTSæ¨¡å—ï¼ˆç«‹å³åŠ è½½æ¨¡å‹ï¼‰
        tts_module = GenieTTSModule()
        
        # åˆ›å»ºæµ‹è¯•é˜Ÿåˆ—
        test_input_queue = queue.Queue()
        test_output_queue = queue.Queue()
        
        # åˆ›å»ºæµ‹è¯•æ–‡æœ¬
        test_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯TTSæ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚"
        print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
        
        # å°†æ–‡æœ¬æ”¾å…¥è¾“å…¥é˜Ÿåˆ—
        test_input_queue.put(TextData(text=test_text, is_finish=True))
        
        # å¯åŠ¨æµå¼å¤„ç†
        print("ğŸ”„ å¼€å§‹æµå¼TTSæµ‹è¯•...")
        tts_module.stream_process(test_input_queue, test_output_queue)
        
        # æ£€æŸ¥è¾“å‡º
        chunk_count = 0
        while True:
            try:
                audio_data = test_output_queue.get(timeout=2.0)
                if audio_data.pcm_data:
                    chunk_count += 1
                    print(f"ğŸ“Š æ”¶åˆ°éŸ³é¢‘åˆ†ç‰‡ #{chunk_count}, å¤§å°: {len(audio_data.pcm_data)} å­—èŠ‚")
                elif audio_data.is_finish:
                    print(f"âœ… æµ‹è¯•å®Œæˆï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªéŸ³é¢‘åˆ†ç‰‡")
                    break
            except queue.Empty:
                print("â³ ç­‰å¾…éŸ³é¢‘åˆ†ç‰‡...")
                break
        
        print("ğŸ‰ TTSæ¨¡å—æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ TTSæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()