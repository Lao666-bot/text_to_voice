# tts_driver.pyï¼ˆç§»é™¤æ‡’åŠ è½½ç‰ˆæœ¬ï¼‰
import os
import asyncio
import queue
import threading
import abc
import numpy as np
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
import time
import wave
import logging
os.environ["GENIE_DATA_DIR"] = r"C:\Users\k\Agent\Genie-TTS\GenieData"
#======================è¿™æ˜¯ä¸€ä¸ªæ—¥å¿—è¿‡æ»¤å™¨ï¼Œç”¨äºè¿‡æ»¤æ‰ç‰¹å®šçš„è­¦å‘Š======================
class GenieTTSFilter(logging.Filter):
    def filter(self, record):
        # è¿‡æ»¤æ‰åŒ…å« "Audio successfully saved" çš„æ—¥å¿—
        if "Audio successfully saved" in record.getMessage():
            return False
        return True
logging.getLogger().addFilter(GenieTTSFilter())
# ===================== 1. å¯¼å…¥æµå¼æ¥å£è§„èŒƒ =====================
@dataclass
class AudioData:
    pcm_data: bytes
    sample_rate: int = 16000
    channels: int = 1
    is_finish: bool = False  # æ ‡è®°æ˜¯å¦æ˜¯æœ€åä¸€ä¸ªéŸ³é¢‘åˆ†ç‰‡
    bit_depth: int = 16      # ä½æ·±

@dataclass
class TextData:
    text: str
    is_finish: bool = True

ChatHistory = List[Dict[str, str]]

class BaseModule(abc.ABC):
    @abc.abstractmethod
    def process(self, input_data) -> Any:
        pass

    @abc.abstractmethod
    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        pass

# ===================== 2. å¯¼å…¥ Genie TTS æ ¸å¿ƒå‡½æ•° =====================
from genie_tts import (
    load_character,
    load_predefined_character,
    set_reference_audio,
    tts,
    tts_async,  # çœŸæ­£çš„æµå¼æ¥å£
    unload_character,
    clear_reference_audio_cache,
    stop,
    wait_for_playback_done
)

# ===================== 3. é…ç½®é¡¹ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰ =====================
LOCAL_MODEL_DIR = r"C:\Users\k\Agent\Genie-TTS\CharacterModels\v2ProPlus\feibi\tts_models"
LOCAL_CHAR_NAME = "feibi"
LOCAL_CHAR_LANG = "Chinese"
REFERENCE_AUDIO_PATH = r"C:\Users\k\Agent\Genie-TTS\CharacterModels\v2ProPlus\feibi\prompt_wav\zh_vo_Main_Linaxita_2_1_10_26.wav"
REFERENCE_AUDIO_TEXT = "åœ¨æ­¤ä¹‹å‰,è¯·æ‚¨åŠ¡å¿…ç»§ç»­äº«å—é›¨å­£æ‹‰å¤çº³çš„æ—¶å…‰"
SAVE_DIR = "./tts_output"

# ===================== 4. Genie TTS æµå¼æ¨¡å—å®ç°ï¼ˆç§»é™¤æ‡’åŠ è½½ï¼‰ =====================
class GenieTTSModule(BaseModule):
    def __init__(self):
        """åˆå§‹åŒ–æ—¶ç«‹å³åŠ è½½æ¨¡å‹ï¼ˆç§»é™¤æ‡’åŠ è½½ï¼‰"""
        print("ğŸ”„ TTSæ¨¡å—åˆå§‹åŒ–ä¸­...")
        
        try:
            # 1. åŠ è½½TTSæ¨¡å‹
            print(f"ğŸ”„ åŠ è½½TTSæ¨¡å‹: {LOCAL_CHAR_NAME}")
            load_character(
                character_name=LOCAL_CHAR_NAME,
                onnx_model_dir=LOCAL_MODEL_DIR,
                language=LOCAL_CHAR_LANG
            )
            print(f"âœ… TTSæ¨¡å‹ {LOCAL_CHAR_NAME} åŠ è½½æˆåŠŸ")
            
            # 2. è®¾ç½®å‚è€ƒéŸ³é¢‘
            print(f"ğŸ”„ è®¾ç½®å‚è€ƒéŸ³é¢‘: {REFERENCE_AUDIO_PATH}")
            set_reference_audio(
                character_name=LOCAL_CHAR_NAME,
                audio_path=REFERENCE_AUDIO_PATH,
                audio_text=REFERENCE_AUDIO_TEXT,
                language=LOCAL_CHAR_LANG
            )
            print(f"âœ… å‚è€ƒéŸ³é¢‘è®¾ç½®æˆåŠŸ")
            
            # 3. æ£€æµ‹éŸ³é¢‘æ ¼å¼
            self._detect_audio_format()
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(SAVE_DIR, exist_ok=True)
            
            print("âœ… TTSæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ TTSæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _detect_audio_format(self):
        """æ£€æµ‹TTSéŸ³é¢‘æ ¼å¼"""
        try:
            # ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
            test_text = "æµ‹è¯•éŸ³é¢‘æ ¼å¼"
            test_path = os.path.join(SAVE_DIR, "format_test.wav")
            
            print(f"ğŸ”„ æ£€æµ‹éŸ³é¢‘æ ¼å¼ï¼Œç”Ÿæˆæµ‹è¯•éŸ³é¢‘...")
            tts(
                character_name=LOCAL_CHAR_NAME,
                text=test_text,
                play=False,
                split_sentence=True,
                save_path=test_path
            )
            
            # åˆ†æWAVæ–‡ä»¶æ ¼å¼
            with wave.open(test_path, 'rb') as wf:
                self.sample_rate = wf.getframerate()
                self.channels = wf.getnchannels()
                self.sample_width = wf.getsampwidth()
                self.bit_depth = self.sample_width * 8
                
                print(f"ğŸ“Š TTSéŸ³é¢‘æ ¼å¼æ£€æµ‹ç»“æœï¼š")
                print(f"   é‡‡æ ·ç‡={self.sample_rate}Hz")
                print(f"   å£°é“={self.channels}")
                print(f"   ä½æ·±={self.bit_depth}bit")
                print(f"   æ ·æœ¬å®½åº¦={self.sample_width}å­—èŠ‚")
            
            # æ¸…ç†æµ‹è¯•æ–‡ä»¶
            try:
                os.remove(test_path)
            except:
                pass
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ ¼å¼æ£€æµ‹å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼
            print("âš ï¸  ä½¿ç”¨é»˜è®¤éŸ³é¢‘æ ¼å¼: 16000Hz/16bit/å•å£°é“")
            self.sample_rate = 16000
            self.channels = 1
            self.bit_depth = 16
            self.sample_width = 2

    def process(self, input_data: TextData) -> AudioData:
        """
        æ‰¹é‡å¤„ç†ï¼ˆéæµå¼ï¼‰ï¼šè¾“å…¥TextDataï¼Œè¾“å‡ºAudioData
        """
        # 1. ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        timestamp = int(time.time())
        save_path = os.path.join(SAVE_DIR, f"{LOCAL_CHAR_NAME}_{timestamp}.wav")
        
        ##print(f"ğŸ”„ æ‰¹é‡å¤„ç†TTS: {input_data.text[:50]}...")
        tts(
            character_name=LOCAL_CHAR_NAME,
            text=input_data.text,
            play=False,
            split_sentence=True,
            save_path=save_path
        )
        
        # 2. è¯»å–éŸ³é¢‘æ–‡ä»¶ä¸ºPCMæ•°æ®
        with open(save_path, "rb") as f:
            pcm_data = f.read()
        
        ##print(f"âœ… æ‰¹é‡TTSå®Œæˆï¼ŒéŸ³é¢‘å¤§å°: {len(pcm_data)} å­—èŠ‚")
        
        # 3. è¿”å›AudioDataæ ¼å¼
        return AudioData(
            pcm_data=pcm_data,
            sample_rate=self.sample_rate,
            channels=self.channels,
            bit_depth=self.bit_depth,
            is_finish=True
        )

    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        """å®æ—¶æµå¼å¤„ç†ï¼šæ¯æ”¶åˆ°ä¸€ä¸ªå¥å­å°±ç«‹å³åˆæˆï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        print("ğŸ”„ å¯åŠ¨å®æ—¶TTSæµå¼å¤„ç†...")
        
        sentence_count = 0
        
        while True:
            try:
                # è·å–æ–‡æœ¬åˆ†ç‰‡ï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼‰
                try:
                    text_data = input_queue.get(timeout=1.0)
                except queue.Empty:
                    continue
                
                # å¦‚æœæ˜¯ç»“æŸæ ‡è®°
                if text_data.is_finish and not text_data.text:
                    output_queue.put(AudioData(
                        pcm_data=b"",
                        sample_rate=self.sample_rate,
                        channels=self.channels,
                        bit_depth=self.bit_depth,
                        is_finish=True
                    ))
                    ##print(f"âœ… TTSæµå¼å¤„ç†å®Œæˆï¼Œå…±åˆæˆ{sentence_count}ä¸ªå¥å­")
                    break
                
                # å¤„ç†å½“å‰æ–‡æœ¬
                text = text_data.text.strip()
                if not text:
                    continue
                
                sentence_count += 1
                ##print(f"ğŸµ TTSå¼€å§‹åˆæˆå¥å­ #{sentence_count}: {text[:50]}...")
                
                # ä½¿ç”¨åŒæ­¥æ–¹æ³•åˆæˆå½“å‰å¥å­
                start_time = time.time()
                
                try:
                    # ä¸ºæ¯ä¸ªå¥å­ç”Ÿæˆä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    timestamp = int(time.time())
                    save_path = os.path.join(SAVE_DIR, f"sentence_{timestamp}_{sentence_count}.wav")
                    
                    # åˆæˆå•ä¸ªå¥å­
                    tts(
                        character_name=LOCAL_CHAR_NAME,
                        text=text,
                        play=False,
                        split_sentence=False,  # å·²ç»æ˜¯å®Œæ•´å¥å­ï¼Œä¸éœ€è¦å†åˆ†å‰²
                        save_path=save_path
                    )
                    
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    with open(save_path, "rb") as f:
                        pcm_data = f.read()
                        ##å»é™¤å¼€å¤´çš„æ°”æ³¡éŸ³
                    pcm_data = self._process_audio_start(pcm_data)
                    
                    elapsed = time.time() - start_time
                    
                    # å‘é€éŸ³é¢‘æ•°æ®
                    output_queue.put(AudioData(
                        pcm_data=pcm_data,
                        sample_rate=self.sample_rate,
                        channels=self.channels,
                        bit_depth=self.bit_depth,
                        is_finish=False
                    ))
                    
                    ##print(f"âœ… TTSå¥å­ #{sentence_count} åˆæˆå®Œæˆï¼Œå¤§å°: {len(pcm_data)} å­—èŠ‚ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.remove(save_path)
                    except:
                        pass
                    
                except Exception as e:
                    print(f"âŒ TTSåˆæˆå¥å­ #{sentence_count} å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                
            except Exception as e:
                print(f"âŒ TTSæµå¼å¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                break
    #======================å»é™¤å¼€å¤´çš„æ°”æ³¡éŸ³=====================
    def _process_audio_start(self, pcm_data: bytes) -> bytes:
        """
        ä¸“é—¨å¤„ç†TTSå¼€å¤´çˆ†ç ´éŸ³çš„å‡½æ•°
        çˆ†ç ´éŸ³ç‰¹å¾ï¼šä½é¢‘èƒ½é‡é«˜ã€çªç„¶çš„èƒ½é‡çˆ†å‘ã€æŒç»­æ—¶é—´çŸ­ï¼ˆ<50msï¼‰
        """
        import numpy as np
        
        # å°†å­—èŠ‚è½¬æ¢ä¸ºnumpyæ•°ç»„
        dtype = np.int16 if self.bit_depth == 16 else np.int32
        samples = np.frombuffer(pcm_data, dtype=dtype)
        
        if len(samples) < 1600:  # å°äº100msçš„éŸ³é¢‘ä¸å¤„ç†
            return pcm_data
        
        # 1. çˆ†ç ´éŸ³ä¸“ç”¨æ£€æµ‹ç®—æ³•
        def detect_plosive_noise(audio_data):
            """æ£€æµ‹çˆ†ç ´éŸ³å™ªéŸ³"""
            # åˆ†æå‰100msï¼ˆ1600ä¸ªæ ·æœ¬ï¼‰
            analysis_length = min(1600, len(audio_data))
            segment = audio_data[:analysis_length].astype(np.float32)
            
            # è®¡ç®—çŸ­æœŸèƒ½é‡ï¼ˆç”¨äºæ£€æµ‹çªå‘èƒ½é‡ï¼‰
            window_size = 160  # 10msçª—å£
            num_windows = analysis_length // window_size
            
            energies = []
            for i in range(num_windows):
                window = segment[i * window_size:(i + 1) * window_size]
                energy = np.sum(window ** 2) / window_size
                energies.append(energy)
            
            # è®¡ç®—èƒ½é‡å˜åŒ–ç‡ï¼ˆçˆ†ç ´éŸ³çš„ç‰¹ç‚¹æ˜¯èƒ½é‡çªç„¶å¢åŠ ï¼‰
            energy_diffs = np.diff(energies)
            
            # æ£€æµ‹èƒ½é‡çªç„¶çˆ†å‘çš„ç‚¹
            sudden_increase_threshold = np.max(energies) * 0.3
            
            for i in range(1, len(energy_diffs)):
                if energy_diffs[i] > sudden_increase_threshold:
                    # çˆ†ç ´éŸ³é€šå¸¸åœ¨å‰3ä¸ªçª—å£å†…
                    if i * window_size < 480:  # å‰30mså†…
                        # å‘å‰æ‰¾æ›´åˆé€‚çš„èµ·å§‹ç‚¹ï¼ˆå¯èƒ½åœ¨çˆ†å‘çš„ç¨å‰ä½ç½®ï¼‰
                        return max(0, (i - 1) * window_size)
            
            return 0
        
        # 2. ä½é¢‘çˆ†ç ´éŸ³æ£€æµ‹ï¼ˆçˆ†ç ´éŸ³é€šå¸¸åœ¨ä½é¢‘ï¼‰
        def detect_low_freq_plosive(audio_data):
            """æ£€æµ‹ä½é¢‘çˆ†ç ´éŸ³"""
            try:
                from scipy import signal
                
                analysis_length = min(800, len(audio_data))
                segment = audio_data[:analysis_length].astype(np.float32)
                
                # è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨ï¼ˆ50-200Hzï¼Œçˆ†ç ´éŸ³ä¸»è¦é¢‘ç‡èŒƒå›´ï¼‰
                lowcut = 50
                highcut = 200
                nyquist = self.sample_rate / 2
                
                # å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨
                b, a = signal.butter(
                    4, 
                    [lowcut/nyquist, highcut/nyquist], 
                    btype='band'
                )
                
                # åº”ç”¨æ»¤æ³¢å™¨
                filtered = signal.filtfilt(b, a, segment)
                
                # è®¡ç®—æ»¤æ³¢åçš„èƒ½é‡
                window_size = 80  # 5ms
                num_windows = analysis_length // window_size
                
                filtered_energies = []
                for i in range(num_windows):
                    window = filtered[i * window_size:(i + 1) * window_size]
                    energy = np.sum(window ** 2) / window_size
                    filtered_energies.append(energy)
                
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªä½é¢‘èƒ½é‡å³°å€¼
                energy_threshold = np.percentile(filtered_energies, 70)
                
                for i, energy in enumerate(filtered_energies):
                    if energy > energy_threshold:
                        # çˆ†ç ´éŸ³é€šå¸¸æŒç»­1-2ä¸ªçª—å£ï¼ˆ5-10msï¼‰
                        return max(0, (i - 1) * window_size)
                        
            except ImportError:
                # scipyä¸å¯ç”¨æ—¶ä½¿ç”¨ç®€åŒ–æ–¹æ³•
                pass
            
            return 0
        
        # 3. ç»éªŒæ³•åˆ™ï¼šæ ¹æ®TTSå¼•æ“ç‰¹æ€§ç›´æ¥åˆ‡é™¤
        def empirical_cut_for_tts():
            """æ ¹æ®ç»éªŒç›´æ¥åˆ‡é™¤å›ºå®šé•¿åº¦"""
            # Genie TTSé€šå¸¸åœ¨å¼€å¤´æœ‰å›ºå®šæ¨¡å¼çš„å™ªéŸ³
            # å°è¯•åˆ‡é™¤å‰30-50msï¼ˆ480-800ä¸ªæ ·æœ¬ï¼‰
            
            # å…ˆæ£€æŸ¥å‰100msçš„èƒ½é‡åˆ†å¸ƒ
            first_100ms = min(1600, len(samples))
            
            # åˆ†æˆ4ä¸ª25msçš„çª—å£
            window_25ms = 400  # 16kHz * 0.025s
            windows = []
            
            for i in range(0, first_100ms, window_25ms):
                if i + window_25ms <= first_100ms:
                    window = samples[i:i+window_25ms]
                    rms = np.sqrt(np.mean(window.astype(np.float64) ** 2))
                    windows.append(rms)
            
            # å¦‚æœç¬¬ä¸€ä¸ªçª—å£èƒ½é‡æ˜æ˜¾é«˜äºåé¢ï¼Œå¾ˆå¯èƒ½æ˜¯å™ªéŸ³
            if len(windows) >= 2 and windows[0] > windows[1] * 1.5:
                return 400  # åˆ‡é™¤å‰25ms
            
            # é»˜è®¤åˆ‡é™¤30msï¼ˆ480ä¸ªæ ·æœ¬ï¼‰
            return 480
        
        # 4. æ³¢å½¢å½¢çŠ¶æ£€æµ‹ï¼ˆçˆ†ç ´éŸ³çš„æ³¢å½¢ç‰¹å¾ï¼‰
        def detect_by_waveform_shape(audio_data):
            """é€šè¿‡æ³¢å½¢å½¢çŠ¶æ£€æµ‹çˆ†ç ´éŸ³"""
            analysis_length = min(800, len(audio_data))
            segment = audio_data[:analysis_length]
            
            # è®¡ç®—æ³¢å½¢çš„ä¸€é˜¶å’ŒäºŒé˜¶å·®åˆ†ï¼ˆæ£€æµ‹çªå˜ï¼‰
            diff1 = np.diff(segment)
            diff2 = np.diff(diff1)
            
            # å¯»æ‰¾å¹…åº¦çªå˜ç‚¹
            amplitude_threshold = np.percentile(np.abs(diff1), 90)
            
            for i in range(len(diff1) - 10):
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸€ç³»åˆ—çš„çªå˜
                if np.abs(diff1[i]) > amplitude_threshold:
                    # æ£€æŸ¥åç»­å‡ ä¸ªç‚¹æ˜¯å¦ä¹Ÿæœ‰è¾ƒå¤§å˜åŒ–
                    subsequent = np.abs(diff1[i:i+10])
                    if np.mean(subsequent) > amplitude_threshold * 0.5:
                        return max(0, i - 20)  # ç¨å¾®æå‰ä¸€ç‚¹
            
            return 0
        
        # 5. ç»¼åˆå¤šç§æ£€æµ‹æ–¹æ³•
        def combined_detection():
            """ç»¼åˆä½¿ç”¨å¤šç§æ£€æµ‹æ–¹æ³•"""
            detection_results = []
            
            # æ–¹æ³•1ï¼šèƒ½é‡çªå˜æ£€æµ‹
            pos1 = detect_plosive_noise(samples)
            if pos1 > 0:
                detection_results.append(pos1)
            
            # æ–¹æ³•2ï¼šä½é¢‘æ£€æµ‹ï¼ˆéœ€è¦scipyï¼‰
            pos2 = detect_low_freq_plosive(samples)
            if pos2 > 0:
                detection_results.append(pos2)
            
            # æ–¹æ³•3ï¼šæ³¢å½¢å½¢çŠ¶æ£€æµ‹
            pos3 = detect_by_waveform_shape(samples)
            if pos3 > 0:
                detection_results.append(pos3)
            
            # æ–¹æ³•4ï¼šç»éªŒåˆ‡é™¤
            pos4 = empirical_cut_for_tts()
            detection_results.append(pos4)
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½è®¤ä¸ºæœ‰å™ªéŸ³ï¼Œå–ä¸­é—´å€¼
            if detection_results:
                # å»æ‰æœ€å¤§æœ€å°å€¼ï¼Œå–ä¸­é—´å€¼
                sorted_results = sorted(detection_results)
                if len(sorted_results) >= 3:
                    # å–ä¸­ä½æ•°
                    return sorted_results[len(sorted_results) // 2]
                else:
                    # å–å¹³å‡å€¼
                    return int(np.mean(sorted_results))
            
            return 480  # é»˜è®¤åˆ‡é™¤30ms
        
        # æ‰§è¡Œæ£€æµ‹
        start_index = combined_detection()
        
        # ç¡®ä¿ä¸ä¼šåˆ‡é™¤å¤ªå¤šï¼ˆä¸è¶…è¿‡20%ï¼Œä¸”ä¸è¶…è¿‡200msï¼‰
        max_cut = min(len(samples) // 5, 3200)  # 200msæˆ–20%
        start_index = min(start_index, max_cut)
        
        # åº”ç”¨åˆ‡é™¤
        if start_index > 0:
            # æ·»åŠ æ›´é•¿çš„æ·¡å…¥æ•ˆæœæ¥å¹³æ»‘è¿‡æ¸¡ï¼ˆ50msï¼‰
            fade_in_length = min(800, len(samples) - start_index)  # 50msæ·¡å…¥
            
            # å¤åˆ¶åˆ‡é™¤åçš„éŸ³é¢‘
            processed_samples = samples[start_index:].copy()
            
            if fade_in_length > 0 and len(processed_samples) > fade_in_length:
                # ä½¿ç”¨æ›´å¹³æ»‘çš„æ·¡å…¥æ›²çº¿ï¼ˆä½™å¼¦æ›²çº¿ï¼‰
                fade_in = np.cos(np.linspace(np.pi/2, 0, fade_in_length))
                processed_samples[:fade_in_length] = (processed_samples[:fade_in_length] * fade_in).astype(dtype)
                
                print(f"  âœ‚ï¸ åˆ‡é™¤ {start_index} æ ·æœ¬ ({start_index/self.sample_rate*1000:.0f}ms)")
            
            # ç¡®ä¿åˆ‡é™¤åéŸ³é¢‘ä¸ä¼šå¤ªçŸ­
            if len(processed_samples) > 1600:  # è‡³å°‘100ms
                return processed_samples.tobytes()
        
        # å¦‚æœæ²¡æœ‰åˆ‡é™¤æˆ–åˆ‡é™¤åå¤ªçŸ­ï¼Œè¿”å›åŸå§‹æ•°æ®
        return pcm_data
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        try:
            print("ğŸ§¹ æ¸…ç†TTSæ¨¡å—èµ„æº...")
            unload_character(character_name=LOCAL_CHAR_NAME)
            clear_reference_audio_cache()
            print("âœ… TTSæ¨¡å—èµ„æºå·²æ¸…ç†")
        except:
            pass


# ===================== 5. æµ‹è¯•ä»£ç  =====================
if __name__ == "__main__":
    # æµ‹è¯•TTSæ¨¡å—
    print("ğŸ§ª æµ‹è¯•TTSæ¨¡å—...")
    
    try:
        # åˆ›å»ºTTSæ¨¡å—ï¼ˆç«‹å³åŠ è½½æ¨¡å‹ï¼‰
        tts_module = GenieTTSModule()
        
        # åˆ›å»ºæµ‹è¯•é˜Ÿåˆ—
        test_input_queue = queue.Queue()
        test_output_queue = queue.Queue()
        
        # åˆ›å»ºæµ‹è¯•æ–‡æœ¬
        test_text = "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯TTSæ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œã€‚"
        print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
        
        # å°†æ–‡æœ¬æ”¾å…¥è¾“å…¥é˜Ÿåˆ—
        test_input_queue.put(TextData(text=test_text, is_finish=True))
        
        # å¯åŠ¨æµå¼å¤„ç†
        print("ğŸ”„ å¼€å§‹æµå¼TTSæµ‹è¯•...")
        tts_module.stream_process(test_input_queue, test_output_queue)
        
        # æ£€æŸ¥è¾“å‡º
        chunk_count = 0
        while True:
            try:
                audio_data = test_output_queue.get(timeout=2.0)
                if audio_data.pcm_data:
                    chunk_count += 1
                    print(f"ğŸ“Š æ”¶åˆ°éŸ³é¢‘åˆ†ç‰‡ #{chunk_count}, å¤§å°: {len(audio_data.pcm_data)} å­—èŠ‚")
                elif audio_data.is_finish:
                    print(f"âœ… æµ‹è¯•å®Œæˆï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªéŸ³é¢‘åˆ†ç‰‡")
                    break
            except queue.Empty:
                print("â³ ç­‰å¾…éŸ³é¢‘åˆ†ç‰‡...")
                break
        
        print("ğŸ‰ TTSæ¨¡å—æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ TTSæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()