# control.py
import gc
import torch
import queue
import threading
import time
from typing import Optional, List
from base_interface import AudioData, TextData, ChatHistory
from llm_zhipu_driver import init_model_and_tokenizer, CUSTOM_SYSTEM_PROMPT, MemorySystem
import keyboard
from sentence_processor import SentenceProcessor
import re

name = "å¦®å¯(Nicole)"

# ===================== å…¨å±€æ§åˆ¶æ ‡è®° =====================
is_recording: bool = False
is_running: bool = True
asr_input_q: Optional[queue.Queue] = None

# ===================== æ¨¡å—å®ä¾‹ =====================
tokenizer = None
llm_model = None

# ===================== æ™ºèƒ½å¥å­åˆ†å‰²å™¨ =====================
class SmartSentenceSplitter:
    """å®æ—¶æ™ºèƒ½åˆ†å¥å™¨"""
    
    def __init__(self, min_chunk_length=5, max_chunk_length=100):
        self.min_length = min_chunk_length
        self.max_length = max_chunk_length
        self.buffer = ""
        
        # å¥å­ç»“æŸç¬¦
        self.endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼›', ';']
        self.weak_endings = ['ï¼Œ', ',', 'ã€', 'ï¼š', ':']
        
    def add_text(self, text):
        """æ·»åŠ æ–‡æœ¬å¹¶è¿”å›å®Œæ•´çš„å¥å­"""
        self.buffer += text
        sentences = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å¥å­ç»“æŸç¬¦çš„ä½ç½®
        end_positions = []
        for ending in self.endings:
            pos = self.buffer.find(ending)
            while pos != -1:
                end_positions.append(pos)
                pos = self.buffer.find(ending, pos + 1)
        
        # æŒ‰ä½ç½®æ’åº
        end_positions.sort()
        
        # æå–å®Œæ•´çš„å¥å­
        last_end = 0
        for pos in end_positions:
            sentence = self.buffer[last_end:pos+1].strip()
            if len(sentence) >= self.min_length:
                sentences.append(sentence)
                last_end = pos + 1
        
        # æ›´æ–°ç¼“å†²åŒº
        self.buffer = self.buffer[last_end:]
        
        # æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦è¿‡é•¿
        if len(self.buffer) > self.max_length:
            # åœ¨å¼±ç»“æŸç¬¦å¤„åˆ†å‰²
            split_pos = -1
            for ending in self.weak_endings:
                pos = self.buffer.rfind(ending)
                if pos > split_pos:
                    split_pos = pos
            
            if split_pos > 0:
                long_sentence = self.buffer[:split_pos+1]
                if long_sentence.strip():
                    sentences.append(long_sentence)
                self.buffer = self.buffer[split_pos+1:]
            else:
                # ç›´æ¥åˆ†å‰²
                long_sentence = self.buffer
                if long_sentence.strip():
                    sentences.append(long_sentence)
                self.buffer = ""
        
        return sentences
    
    def flush(self):
        """æ¸…ç©ºç¼“å†²åŒºï¼Œè¿”å›å‰©ä½™å†…å®¹"""
        remaining = self.buffer
        self.buffer = ""
        return remaining

# ===================== åˆå§‹åŒ–å‡½æ•° =====================
def memory_cleanup():
    """æ¸…ç†æ˜¾å­˜å’Œå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()

def init_control_modules():
    """åˆå§‹åŒ–LLMç›¸å…³æ¨¡å—"""
    global tokenizer, llm_model
    tokenizer, llm_model, _ = init_model_and_tokenizer()
    print("âœ… æ§åˆ¶æ¨¡å—åˆå§‹åŒ–å®Œæˆ")

# ===================== çœŸæ­£çš„å¼‚æ­¥æµå¼ç”Ÿæˆ =====================
def create_async_stream_generator(user_input, history=None, memory_system=None, temperature=0.8):
    """åˆ›å»ºå¼‚æ­¥æµå¼ç”Ÿæˆå™¨"""
    
    # å‡†å¤‡è®°å¿†ä¸Šä¸‹æ–‡
    memory_context = ""
    if memory_system:
        try:
            memory_context = memory_system.get_memory_context(user_input)
            if memory_context and "ï¼ˆæš‚æ— è®°å¿†ï¼‰" not in memory_context:
                print(f"ğŸ§  ä½¿ç”¨è®°å¿†: {memory_context[:50]}...")
        except Exception as e:
            print(f"âš ï¸ è®°å¿†ç³»ç»Ÿé”™è¯¯: {e}")
    
    # æ„å»ºåŠ¨æ€æç¤ºè¯
    dynamic_prompt = CUSTOM_SYSTEM_PROMPT.format(
        memory_context=memory_context
    )
    
    # å‡†å¤‡å¯¹è¯å†å²
    if not history or history[0].get("role") != "system":
        history = [{"role": "system", "content": dynamic_prompt}]
    else:
        history[0]["content"] = dynamic_prompt
    
    ##print(f"ğŸš€ LLMå¼€å§‹å¼‚æ­¥ç”Ÿæˆ...")
    
    # ä½¿ç”¨çº¿ç¨‹å®ç°çœŸæ­£çš„å¼‚æ­¥
    result_queue = queue.Queue()
    
    def generate_stream():
        """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ç”Ÿæˆæµ"""
        try:
            full_response = ""
            
            # ä½¿ç”¨æ¨¡å‹çš„stream_chatæ–¹æ³•
            for response, new_history, _ in llm_model.stream_chat(
                tokenizer=tokenizer,
                query=user_input,
                history=history,
                top_p=0.9,
                temperature=temperature,
                system=dynamic_prompt,
                past_key_values=None,
                return_past_key_values=True
            ):
                # è¿‡æ»¤AIèº«ä»½å…³é”®è¯
                filter_words = ["AI", "åŠ©æ‰‹", "ChatGLM", "æ¨¡å‹", "è®­ç»ƒ", "å¼€å‘", "æ™ºè°±", "äººå·¥æ™ºèƒ½"]
                filtered_response = response
                for word in filter_words:
                    filtered_response = filtered_response.replace(word, "")
                
                # æå–æ–°å¢çš„å†…å®¹
                if len(filtered_response) > len(full_response):
                    new_content = filtered_response[len(full_response):]
                    full_response = filtered_response
                    
                    if new_content:
                        # å°†æ–°å†…å®¹æ”¾å…¥é˜Ÿåˆ—
                        result_queue.put(("chunk", new_content))
            
            # ç”Ÿæˆå®Œæˆ
            result_queue.put(("complete", full_response))
            
        except Exception as e:
            print(f"âŒ LLMæµå¼ç”Ÿæˆé”™è¯¯: {e}")
            result_queue.put(("error", str(e)))
    
    # å¯åŠ¨ç”Ÿæˆçº¿ç¨‹
    gen_thread = threading.Thread(target=generate_stream, daemon=True)
    gen_thread.start()
    
    # è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œä»é˜Ÿåˆ—ä¸­è¯»å–ç»“æœ
    while True:
        try:
            item_type, data = result_queue.get(timeout=30)  # 30ç§’è¶…æ—¶
            
            if item_type == "chunk":
                yield data, False, ""
            elif item_type == "complete":
                yield "", True, data
                break
            elif item_type == "error":
                raise Exception(f"LLMç”Ÿæˆé”™è¯¯: {data}")
                
        except queue.Empty:
            print("â³ LLMç”Ÿæˆè¶…æ—¶")
            break

# ===================== å¼‚æ­¥LLM-TTSæµæ°´çº¿ =====================
def asr_to_llm(asr_output_q: queue.Queue, tts_input_q: queue.Queue):
    """ASR â†’ LLM â†’ TTSï¼ˆçœŸæ­£çš„å¼‚æ­¥æµæ°´çº¿ï¼‰"""
    
    memory_system = MemorySystem()
    sentence_processor = SentenceProcessor(min_length=3, max_silence=1.5)
    sentence_queue = queue.Queue()
    
    # å¯åŠ¨å¥å­å¤„ç†çº¿ç¨‹
    def process_asr_output():
        while is_running:
            try:
                asr_text = asr_output_q.get(timeout=0.1)
                sentence_processor.process(asr_text, sentence_queue)
            except queue.Empty:
                continue
    
    # LLM-TTSå¹¶è¡Œå¤„ç†çº¿ç¨‹
    def process_conversation():
        while is_running:
            try:
                sentence_data = sentence_queue.get(timeout=0.1)
                if not sentence_data.text:
                    continue
                
                user_input = sentence_data.text
                
                print(f"\nğŸ‘¤ ç”¨æˆ·è¯´: {user_input}")
                print("="*50)
                
                print(f"ğŸ¤– {name}: ", end="", flush=True)
                
                # æ£€æŸ¥è®°å¿†å…³é”®è¯
                force_memory = any(keyword in user_input for keyword in ['ä¹‹å‰', 'åˆšæ‰', 'è®°å¾—', 'è¯´è¿‡', 'å‘Šè¯‰è¿‡'])
                if force_memory:
                    print("ğŸ§  æ£€æµ‹åˆ°è®°å¿†å…³é”®è¯ï¼Œå¼ºåˆ¶ä½¿ç”¨è®°å¿†...")
                
                # åˆ›å»ºæ™ºèƒ½åˆ†å¥å™¨
                sentence_splitter = SmartSentenceSplitter(min_length=3, max_length=40)
                
                # å¼€å§‹å¼‚æ­¥æµå¼ç”Ÿæˆ
                start_time = time.time()
                tts_chunks_sent = 0
                full_response = ""
                
                # ä½¿ç”¨å¼‚æ­¥æµå¼ç”Ÿæˆå™¨
                for chunk, is_final, final_response in create_async_stream_generator(
                    user_input,
                    memory_system=memory_system,
                    temperature=0.2 if force_memory else 0.8
                ):
                    if chunk:
                        # æ‰“å°chunk
                        print(chunk, end="", flush=True)
                        full_response += chunk
                        
                        # æ·»åŠ åˆ°åˆ†å¥å™¨
                        sentences = sentence_splitter.add_text(chunk)
                        
                        # å‘é€å®Œæ•´çš„å¥å­åˆ°TTS
                        for sentence in sentences:
                            if sentence.strip():
                                tts_chunks_sent += 1
                                # print(f"\nğŸ“¤ å‘é€TTSåˆ†ç‰‡#{tts_chunks_sent}: {sentence}")
                                tts_input_q.put(TextData(text=sentence, is_finish=False))
                    
                    if is_final:
                        # å‘é€å‰©ä½™çš„æ–‡æœ¬
                        remaining = sentence_splitter.flush()
                        if remaining.strip():
                            tts_chunks_sent += 1
                            # print(f"\nğŸ“¤ å‘é€æœ€ç»ˆTTSåˆ†ç‰‡#{tts_chunks_sent}: {remaining}")
                            tts_input_q.put(TextData(text=remaining, is_finish=False))
                        
                        # å‘é€ç»“æŸæ ‡è®°
                        tts_input_q.put(TextData(text="", is_finish=True))
                        
                        # æ›´æ–°è®°å¿†
                        memory_system.add_conversation(user_input, final_response)
                        
                        end_time = time.time()
                        print(f"\nâ±ï¸  å“åº”æ—¶é—´: {end_time - start_time:.2f}ç§’")
                        print(f"ğŸ“¤ å…±å‘é€{tts_chunks_sent}ä¸ªTTSåˆ†ç‰‡")
                        break
                
                print(f"\n{'='*50}")
                
                # å†…å­˜æ¸…ç†
                memory_cleanup()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"\nâŒ å¯¹è¯å¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                error_text = "æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æœ‰ç‚¹èµ°ç¥äº†ï¼Œæˆ‘ä»¬ç»§ç»­èŠå§ã€‚"
                tts_input_q.put(TextData(text=error_text, is_finish=True))
                continue
    
    # å¯åŠ¨çº¿ç¨‹
    asr_thread = threading.Thread(target=process_asr_output, name="ASRå¤„ç†")
    conv_thread = threading.Thread(target=process_conversation, name="å¯¹è¯å¤„ç†")
    
    asr_thread.daemon = True
    conv_thread.daemon = True
    
    asr_thread.start()
    conv_thread.start()
    
    # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    try:
        while is_running:
            time.sleep(0.1)
    finally:
        asr_thread.join(timeout=1)
        conv_thread.join(timeout=1)

# ===================== TTSæ’­æ”¾ =====================
def tts_to_play(tts_output_q: queue.Queue, audio_driver):
    """TTSåˆæˆç»“æœ â†’ éŸ³é¢‘æ’­æ”¾"""
    audio_chunk_count = 0
    
    while is_running:
        try:
            audio_data: AudioData = tts_output_q.get(timeout=0.1)
        except queue.Empty:
            continue
        
        if audio_data.pcm_data == b"":
            audio_driver.push_audio_for_play(audio_data)
            audio_chunk_count = 0
            continue
        
        audio_chunk_count += 1
        chunk_size = len(audio_data.pcm_data)
        
        if hasattr(audio_data, 'sample_rate') and audio_data.sample_rate > 0:
            bytes_per_sample = audio_data.bit_depth // 8 if hasattr(audio_data, 'bit_depth') else 2
            channels = audio_data.channels if hasattr(audio_data, 'channels') else 1
            samples = chunk_size / (bytes_per_sample * channels)
            duration_ms = (samples / audio_data.sample_rate) * 1000
            duration_str = f", æ—¶é•¿â‰ˆ{duration_ms:.1f}ms"
        else:
            duration_str = ""
        
        print(f"ğŸµ éŸ³é¢‘åˆ†ç‰‡ #{audio_chunk_count}, å¤§å°: {chunk_size}å­—èŠ‚{duration_str}")
        
        audio_driver.push_audio_for_play(audio_data)

# ===================== æŒ‰é”®æ§åˆ¶ =====================
def key_control(audio_driver):
    """æŒ‰é”®æ§åˆ¶çº¿ç¨‹"""
    global is_recording, is_running, asr_input_q
    
    print("="*50)
    print("ğŸ™ï¸  æµå¼è¯­éŸ³äº¤äº’ç³»ç»Ÿ")
    print("â†’ æŒ‰ã€ç©ºæ ¼é”®ã€‘ï¼šå¼€å§‹/åœæ­¢è¯­éŸ³è¾“å…¥")
    print("â†’ æŒ‰ã€ESCé”®ã€‘ï¼šé€€å‡ºç¨‹åº")
    print("="*50)
    
    last_space_press = 0
    debounce_time = 0.5
    
    while is_running:
        try:
            current_time = time.time()
            
            # ç©ºæ ¼é”®åˆ‡æ¢å½•éŸ³
            if keyboard.is_pressed('space') and (current_time - last_space_press) > debounce_time:
                last_space_press = current_time
                is_recording = not is_recording
                if is_recording:
                    print("\nâ–¶ï¸  å¼€å§‹å½•éŸ³...")
                    audio_driver.start_record(chunk_duration=0.6)
                else:
                    print("\nâ¹ï¸  åœæ­¢å½•éŸ³...")
                    audio_driver.stop_record()
                    if asr_input_q is not None:
                        asr_input_q.put(AudioData(pcm_data=b"", sample_rate=16000, channels=1, is_finish=True))
            
            # ESCé”®é€€å‡º
            if keyboard.is_pressed('esc'):
                print("\nğŸ›‘ é€€å‡ºç¨‹åº...")
                is_running = False
                is_recording = False
                break
            
            time.sleep(0.05)
            
        except Exception as e:
            print(f"âŒ¨ï¸ æŒ‰é”®æ§åˆ¶å¼‚å¸¸: {e}")
            break
    
    print("âŒ¨ï¸ æŒ‰é”®æ§åˆ¶çº¿ç¨‹é€€å‡º")

# ===================== èµ„æºæ¸…ç† =====================
def cleanup():
    """æ¸…ç†å…¨å±€çŠ¶æ€å’Œèµ„æº"""
    global is_running, is_recording, asr_input_q
    is_running = False
    is_recording = False
    asr_input_q = None
    print("âœ… æ§åˆ¶æ¨¡å—èµ„æºå·²æ¸…ç†")

# ===================== è®°å¿†ä¿å­˜/åŠ è½½ =====================
def save_memory(memory_system):
    """ä¿å­˜è®°å¿†åˆ°æ–‡ä»¶"""
    try:
        import json
        memory_data = {
            "long_term_memory": memory_system.long_term_memory,
            "user_profile": memory_system.user_profile,
            "save_time": time.time()
        }
        
        with open("memory_backup.json", "w", encoding="utf-8") as f:
            json.dump(memory_data, f, ensure_ascii=False, indent=2)
        print("âœ… è®°å¿†å·²ä¿å­˜")
    except Exception as e:
        print(f"âŒ è®°å¿†ä¿å­˜å¤±è´¥: {e}")

def load_memory():
    """ä»æ–‡ä»¶åŠ è½½è®°å¿†"""
    try:
        import json
        import os
        
        if os.path.exists("memory_backup.json"):
            with open("memory_backup.json", "r", encoding="utf-8") as f:
                memory_data = json.load(f)
            
            memory_system = MemorySystem()
            memory_system.long_term_memory = memory_data.get("long_term_memory", [])
            memory_system.user_profile = memory_data.get("user_profile", {})
            print("âœ… è®°å¿†å·²åŠ è½½")
            return memory_system
    except Exception as e:
        print(f"âŒ è®°å¿†åŠ è½½å¤±è´¥: {e}")
    
    return MemorySystem()
def text_to_llm(text_input: str, tts_input_q: queue.Queue):
    """
    æ–‡æœ¬æ¨¡å¼ä¸‹çš„LLM-TTSå¼‚æ­¥æµæ°´çº¿
    """
    memory_system = MemorySystem()
    
    # åˆ›å»ºæ™ºèƒ½åˆ†å¥å™¨
    sentence_splitter = SmartSentenceSplitter(min_chunk_length=3, max_chunk_length=40)
    
    print(f"\nğŸ‘¤ ç”¨æˆ·è¾“å…¥: {text_input}")
    print("=" * 50)
    
    print(f"ğŸ¤– {name}: ", end="", flush=True)
    
    # æ£€æŸ¥è®°å¿†å…³é”®è¯
    force_memory = any(keyword in text_input for keyword in ['ä¹‹å‰', 'åˆšæ‰', 'è®°å¾—', 'è¯´è¿‡', 'å‘Šè¯‰è¿‡'])
    if force_memory:
        print("ğŸ§  æ£€æµ‹åˆ°è®°å¿†å…³é”®è¯ï¼Œå¼ºåˆ¶ä½¿ç”¨è®°å¿†...")
    
    # å¼€å§‹å¼‚æ­¥æµå¼ç”Ÿæˆ
    start_time = time.time()
    tts_chunks_sent = 0
    full_response = ""
    
    try:
        # ä½¿ç”¨å¼‚æ­¥æµå¼ç”Ÿæˆå™¨
        for chunk, is_final, final_response in create_async_stream_generator(
            text_input,
            memory_system=memory_system,
            temperature=0.2 if force_memory else 0.8
        ):
            if chunk:
                # æ‰“å°chunk
                print(chunk, end="", flush=True)
                full_response += chunk
                
                # æ·»åŠ åˆ°åˆ†å¥å™¨
                sentences = sentence_splitter.add_text(chunk)
                
                # å‘é€å®Œæ•´çš„å¥å­åˆ°TTS
                for sentence in sentences:
                    if sentence.strip():
                        tts_chunks_sent += 1
                        # print(f"\nğŸ“¤ å‘é€TTSåˆ†ç‰‡#{tts_chunks_sent}: {sentence}")
                        tts_input_q.put(TextData(text=sentence, is_finish=False))
            
            if is_final:
                # å‘é€å‰©ä½™çš„æ–‡æœ¬
                remaining = sentence_splitter.flush()
                if remaining.strip():
                    tts_chunks_sent += 1
                    # print(f"\nğŸ“¤ å‘é€æœ€ç»ˆTTSåˆ†ç‰‡#{tts_chunks_sent}: {remaining}")
                    tts_input_q.put(TextData(text=remaining, is_finish=False))
                
                # å‘é€ç»“æŸæ ‡è®°
                tts_input_q.put(TextData(text="", is_finish=True))
                
                # æ›´æ–°è®°å¿†
                memory_system.add_conversation(text_input, final_response)
                
                end_time = time.time()
                print(f"\nâ±ï¸  å“åº”æ—¶é—´: {end_time - start_time:.2f}ç§’")
                print(f"ğŸ“¤ å…±å‘é€{tts_chunks_sent}ä¸ªTTSåˆ†ç‰‡")
                break
        
        print(f"\n{'=' * 50}")
        
        return full_response
        
    except Exception as e:
        print(f"\nâŒ LLMå¤„ç†é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        error_text = "æŠ±æ­‰ï¼Œæˆ‘åˆšæ‰æœ‰ç‚¹èµ°ç¥äº†ï¼Œæˆ‘ä»¬ç»§ç»­èŠå§ã€‚"
        tts_input_q.put(TextData(text=error_text, is_finish=True))
        return ""