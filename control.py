# control.py å¼€å¤´ä¿®æ”¹å¯¼å…¥
import gc
import torch
import queue
import threading
import time
from typing import Optional
from base_interface import AudioData, TextData, ChatHistory
from llm_zhipu_driver import init_model_and_tokenizer, CUSTOM_SYSTEM_PROMPT, create_stream_generator
import keyboard  # éœ€å®‰è£…ï¼špip install keyboard
from sentence_processor import SentenceProcessor
name="å¦®å¯(Nicole)"
# ===================== å…¨å±€æ§åˆ¶æ ‡è®° =====================
is_recording: bool = False  # æ˜¯å¦æ¿€æ´»è¯­éŸ³è¯†åˆ«
is_running: bool = True     # ç¨‹åºæ˜¯å¦è¿è¡Œ
asr_input_q: Optional[queue.Queue] = None    # å…¨å±€ASRè¾“å…¥é˜Ÿåˆ—

# ===================== æ¨¡å—å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰ =====================
tokenizer = None
llm_model = None

# ===================== åˆå§‹åŒ–å‡½æ•° =====================
def memory_cleanup():
    """æ¸…ç†æ˜¾å­˜å’Œå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()
def init_control_modules():
    """åˆå§‹åŒ–LLMç›¸å…³æ¨¡å—ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰"""
    global tokenizer, llm_model
    tokenizer, llm_model = init_model_and_tokenizer()
    print("âœ… æ§åˆ¶æ¨¡å—ï¼ˆLLMï¼‰åˆå§‹åŒ–å®Œæˆ")

# ===================== æ¡¥æ¥å‡½æ•°å°è£… =====================
def asr_to_llm(asr_output_q: queue.Queue, tts_input_q: queue.Queue):
    """ASR â†’ å¥å­å¤„ç†å™¨ â†’ LLM"""
    # ä½¿ç”¨è‡ªå®šä¹‰system promptåˆå§‹åŒ–å¯¹è¯å†å²
    chat_history = [{"role": "system", "content": CUSTOM_SYSTEM_PROMPT}]
    sentence_processor = SentenceProcessor(min_length=3, max_silence=1.5)
    sentence_queue = queue.Queue()  # å­˜å‚¨å®Œæ•´å¥å­
    
    # å¯åŠ¨å¥å­å¤„ç†çº¿ç¨‹
    def process_asr_output():
        while is_running:
            try:
                asr_text = asr_output_q.get(timeout=0.1)
                sentence_processor.process(asr_text, sentence_queue)
            except queue.Empty:
                continue
    
    # å¯åŠ¨LLMå¤„ç†çº¿ç¨‹
    def process_sentences():
        nonlocal chat_history  # å£°æ˜ä¸ºnonlocalå˜é‡
        while is_running:
            try:
                sentence_data = sentence_queue.get(timeout=0.1)
                if not sentence_data.text:
                    continue
                
                # è°ƒç”¨LLM
                print(f"\nğŸ‘¤ ç”¨æˆ·è¯´: {sentence_data.text}")
                print("="*50)
                
                if llm_model is None or tokenizer is None:
                    continue
                
                print(f"ğŸ¤– {name}: ", end="", flush=True)
                full_response = ""
                
                # ä½¿ç”¨æµå¼ç”Ÿæˆå™¨
                for chunk, new_history in create_stream_generator(
                    tokenizer=tokenizer,
                    model=llm_model,
                    query=sentence_data.text,
                    history=chat_history
                ):
                    if chunk:
                        print(chunk, end="", flush=True)
                        full_response += chunk
                        tts_input_q.put(TextData(text=chunk, is_finish=False))
                
                # æ›´æ–°å¯¹è¯å†å²
                chat_history = new_history if new_history else chat_history
                
                # å‘é€ç»“æŸæ ‡è®°
                tts_input_q.put(TextData(text="", is_finish=True))
                print(f"\n{'='*50}")
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"\nâŒ LLMå¤„ç†é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                # å‘é€é”™è¯¯æç¤ºç»™TTS
                error_text = "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
                tts_input_q.put(TextData(text=error_text, is_finish=True))
                tts_input_q.put(TextData(text="", is_finish=True))
                continue
    
    # å¯åŠ¨ä¸¤ä¸ªçº¿ç¨‹
    asr_thread = threading.Thread(target=process_asr_output, name="ASRå¥å­å¤„ç†")
    llm_thread = threading.Thread(target=process_sentences, name="LLMå¤„ç†")
    
    asr_thread.daemon = True
    llm_thread.daemon = True
    
    asr_thread.start()
    llm_thread.start()
    
    # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    try:
        while is_running:
            time.sleep(0.1)
    finally:
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        asr_thread.join(timeout=1)
        llm_thread.join(timeout=1)
    def process_sentences():
        nonlocal chat_history
        while is_running:
            try:
                # æ¯æ¬¡å¤„ç†å‰æ¸…ç†å†…å­˜
                memory_cleanup()
                
                sentence_data = sentence_queue.get(timeout=0.1)
                if not sentence_data.text:
                    continue
                
                # å¤„ç†å®Œæˆåå†æ¬¡æ¸…ç†
                # ...
                
                # æ¸…ç†å†å²è®°å½•ï¼Œåªä¿ç•™æœ€è¿‘å‡ è½®
                if len(chat_history) > 10:  # é™åˆ¶å¯¹è¯å†å²é•¿åº¦
                    chat_history = [chat_history[0]] + chat_history[-8:]  # ä¿ç•™ç³»ç»Ÿæç¤ºå’Œæœ€è¿‘å¯¹è¯
                    
            except queue.Empty:
                continue
            finally:
                # ç¡®ä¿æ¸…ç†
                memory_cleanup()


def tts_to_play(tts_output_q: queue.Queue, audio_driver):
    """
    TTSåˆæˆç»“æœ â†’ éŸ³é¢‘æ’­æ”¾ï¼ˆä¿®å¤å¤šæ¬¡æ’­æ”¾é€»è¾‘ï¼Œæ”¯æŒéŸ³é¢‘æ ¼å¼é€ä¼ ï¼‰
    :param tts_output_q: TTSè¾“å‡ºé˜Ÿåˆ—ï¼ˆAudioDataï¼‰
    :param audio_driver: éŸ³é¢‘é©±åŠ¨å®ä¾‹ï¼ˆAudioDriverï¼‰
    """
    audio_chunk_count = 0
    
    while is_running:
        # 1. è¯»å–TTSåˆæˆçš„éŸ³é¢‘åˆ†ç‰‡ï¼ˆéé˜»å¡ï¼‰
        try:
            audio_data: AudioData = tts_output_q.get(timeout=0.1)
        except queue.Empty:
            continue
        
        # 2. å¤„ç†ç»“æŸæ ‡è®°ï¼šä»…æ¨é€ç©ºæ•°æ®ï¼Œä¸ç»ˆæ­¢å¾ªç¯
        if audio_data.pcm_data == b"":
            # æ¨é€ç»“æŸæ ‡è®°ï¼ˆé‡ç½®æ’­æ”¾æµï¼‰
            audio_driver.push_audio_for_play(audio_data)
            print(f"ğŸµ æ”¶åˆ°TTSç»“æŸæ ‡è®°ï¼ˆç¬¬{audio_chunk_count}ä¸ªåˆ†ç‰‡åï¼‰")
            audio_chunk_count = 0  # é‡ç½®è®¡æ•°
            continue
        
        # 3. è°ƒç”¨éŸ³é¢‘é©±åŠ¨æ’­æ”¾æ¥å£ï¼ˆé€ä¼ TTSçš„åŸå§‹éŸ³é¢‘æ ¼å¼ï¼‰
        audio_chunk_count += 1
        chunk_size = len(audio_data.pcm_data)
        
        # è®¡ç®—éŸ³é¢‘æ—¶é•¿
        if hasattr(audio_data, 'sample_rate') and audio_data.sample_rate > 0:
            # å‡è®¾æ˜¯16ä½PCMï¼ˆ2å­—èŠ‚/æ ·æœ¬ï¼‰
            bytes_per_sample = audio_data.bit_depth // 8 if hasattr(audio_data, 'bit_depth') else 2
            channels = audio_data.channels if hasattr(audio_data, 'channels') else 1
            samples = chunk_size / (bytes_per_sample * channels)
            duration_ms = (samples / audio_data.sample_rate) * 1000
            duration_str = f", æ—¶é•¿â‰ˆ{duration_ms:.1f}ms"
        else:
            duration_str = ""
        
        print(f"ğŸµ æ¨é€éŸ³é¢‘åˆ†ç‰‡ #{audio_chunk_count}, "
              f"å¤§å°: {chunk_size} å­—èŠ‚{duration_str}")
        
        audio_driver.push_audio_for_play(audio_data)

def key_control(audio_driver):
    """
    æŒ‰é”®æ§åˆ¶çº¿ç¨‹ï¼šç©ºæ ¼=å¯åŠ¨/åœæ­¢è¯†åˆ«ï¼ŒESC=é€€å‡ºç¨‹åº
    å¢åŠ é˜²æŠ–å’ŒçŠ¶æ€æ£€æŸ¥ï¼Œé¿å…é˜»å¡
    """
    global is_recording, is_running, asr_input_q
    
    print("="*50)
    print("ğŸ™ï¸  æµå¼è¯­éŸ³äº¤äº’ç³»ç»Ÿ")
    print("â†’ æŒ‰ã€ç©ºæ ¼é”®ã€‘ï¼šå¼€å§‹/åœæ­¢è¯­éŸ³è¾“å…¥")
    print("â†’ æŒ‰ã€ESCé”®ã€‘ï¼šé€€å‡ºç¨‹åº")
    print("="*50)
    
    last_space_press = 0
    debounce_time = 0.5  # é˜²æŠ–æ—¶é—´500ms
    
    while is_running:
        try:
            current_time = time.time()
            
            # ç©ºæ ¼é”®ï¼šåˆ‡æ¢å½•éŸ³çŠ¶æ€ï¼ˆå¸¦é˜²æŠ–ï¼‰
            if keyboard.is_pressed('space') and (current_time - last_space_press) > debounce_time:
                last_space_press = current_time
                is_recording = not is_recording
                if is_recording:
                    print("\nâ–¶ï¸  å·²å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼Œå¼€å§‹è¯´è¯...")
                    audio_driver.start_record(chunk_duration=0.6)
                else:
                    print("\nâ¹ï¸  å·²åœæ­¢è¯­éŸ³è¯†åˆ«ï¼Œæ­£åœ¨å¤„ç†ç»“æœ...")
                    audio_driver.stop_record()
                    # å‘é€ASRç»“æŸæ ‡è®°
                    if asr_input_q is not None:
                        asr_input_q.put(AudioData(pcm_data=b"", sample_rate=16000, channels=1, is_finish=True))
            
            # ESCé”®ï¼šé€€å‡ºç¨‹åº
            if keyboard.is_pressed('esc'):
                print("\nğŸ›‘ æ”¶åˆ°é€€å‡ºæŒ‡ä»¤ï¼Œæ­£åœ¨å…³é—­ç³»ç»Ÿ...")
                is_running = False
                is_recording = False
                break
            
            time.sleep(0.05)  # ç¨å¾®é™ä½è½®è¯¢é¢‘ç‡
            
        except Exception as e:
            print(f"âŒ¨ï¸  æŒ‰é”®æ§åˆ¶å¼‚å¸¸: {e}")
            break
    
    print("âŒ¨ï¸  æŒ‰é”®æ§åˆ¶çº¿ç¨‹é€€å‡º")

# ===================== èµ„æºæ¸…ç†å‡½æ•° =====================
def cleanup():
    """æ¸…ç†å…¨å±€çŠ¶æ€å’Œèµ„æº"""
    global is_running, is_recording, asr_input_q
    is_running = False
    is_recording = False
    asr_input_q = None
    print("âœ… æ§åˆ¶æ¨¡å—èµ„æºå·²æ¸…ç†")