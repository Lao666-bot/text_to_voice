# audio_debug.py
import queue
import time
import threading
import wave
import os
from tts_driver import GenieTTSModule
from base_interface import TextData, AudioData

class AudioDebugger:
    """éŸ³é¢‘è°ƒè¯•å·¥å…·"""
    
    def __init__(self, tts_module):
        self.tts_module = tts_module
        self.audio_chunks = []
        self.audio_durations = []
        
    def test_tts_streaming(self, text, max_sentences=10):
        """æµ‹è¯•TTSæµå¼è¾“å‡º"""
        print(f"ğŸ” æµ‹è¯•TTSæµå¼è¾“å‡º: '{text[:50]}...'")
        
        # åˆ›å»ºé˜Ÿåˆ—
        input_queue = queue.Queue()
        output_queue = queue.Queue()
        
        # å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­
        sentences = self._split_into_sentences(text, max_sentences)
        
        print(f"ğŸ“ å°†æ–‡æœ¬åˆ†å‰²ä¸º {len(sentences)} ä¸ªå¥å­:")
        for i, sentence in enumerate(sentences):
            print(f"  {i+1}. {sentence[:50]}...")
            input_queue.put(TextData(text=sentence, is_finish=(i == len(sentences)-1)))
        
        # å¯åŠ¨TTSå¤„ç†çº¿ç¨‹
        def tts_worker():
            self.tts_module.stream_process(input_queue, output_queue)
        
        tts_thread = threading.Thread(target=tts_worker)
        tts_thread.start()
        
        # æ”¶é›†éŸ³é¢‘æ•°æ®
        chunk_count = 0
        start_time = time.time()
        
        while True:
            try:
                audio_data = output_queue.get(timeout=2.0)
                
                if audio_data.pcm_data == b"":
                    print(f"âœ… æ”¶åˆ°ç»“æŸæ ‡è®°ï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªéŸ³é¢‘åˆ†ç‰‡")
                    break
                
                chunk_count += 1
                self.audio_chunks.append(audio_data.pcm_data)
                
                # è®¡ç®—æ—¶é•¿
                if hasattr(audio_data, 'sample_rate') and audio_data.sample_rate > 0:
                    bytes_per_sample = audio_data.bit_depth // 8 if hasattr(audio_data, 'bit_depth') else 2
                    channels = audio_data.channels if hasattr(audio_data, 'channels') else 1
                    samples = len(audio_data.pcm_data) / (bytes_per_sample * channels)
                    duration_ms = (samples / audio_data.sample_rate) * 1000
                    self.audio_durations.append(duration_ms)
                    print(f"ğŸµ éŸ³é¢‘åˆ†ç‰‡ #{chunk_count}: {len(audio_data.pcm_data)}å­—èŠ‚, {duration_ms:.0f}ms")
                else:
                    print(f"ğŸµ éŸ³é¢‘åˆ†ç‰‡ #{chunk_count}: {len(audio_data.pcm_data)}å­—èŠ‚")
                
            except queue.Empty:
                print("â³ ç­‰å¾…éŸ³é¢‘è¶…æ—¶ï¼Œå¯èƒ½å·²ç»“æŸ")
                break
        
        tts_thread.join(timeout=5)
        
        total_duration = sum(self.audio_durations) / 1000  # è½¬æ¢ä¸ºç§’
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"  éŸ³é¢‘åˆ†ç‰‡æ•°é‡: {len(self.audio_chunks)}")
        print(f"  æ€»éŸ³é¢‘æ—¶é•¿: {total_duration:.2f}ç§’")
        print(f"  æ¯ä¸ªåˆ†ç‰‡å¹³å‡æ—¶é•¿: {total_duration/len(self.audio_durations)*1000:.0f}ms" if self.audio_durations else "N/A")
        
        # ä¿å­˜éŸ³é¢‘ç”¨äºåˆ†æ
        self._save_audio_for_analysis()
        
        return len(self.audio_chunks)
    
    def _split_into_sentences(self, text, max_sentences):
        """ç®€å•å¥å­åˆ†å‰²"""
        import re
        # ä½¿ç”¨æ ‡ç‚¹ç¬¦å·åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!?]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # é™åˆ¶å¥å­æ•°é‡
        if len(sentences) > max_sentences:
            sentences = sentences[:max_sentences]
        
        return sentences
    
    def _save_audio_for_analysis(self):
        """ä¿å­˜éŸ³é¢‘ç”¨äºåˆ†æ"""
        if not self.audio_chunks:
            print("âš ï¸ æ²¡æœ‰éŸ³é¢‘æ•°æ®å¯ä¿å­˜")
            return
        
        os.makedirs("audio_debug", exist_ok=True)
        
        # ä¿å­˜æ¯ä¸ªåˆ†ç‰‡
        for i, chunk in enumerate(self.audio_chunks):
            filename = f"audio_debug/chunk_{i+1:03d}.wav"
            with wave.open(filename, 'wb') as wf:
                wf.setnchannels(1)  # å•å£°é“
                wf.setsampwidth(2)  # 16bit = 2å­—èŠ‚
                wf.setframerate(16000)  # 16kHz
                wf.writeframes(chunk)
            print(f"ğŸ’¾ ä¿å­˜åˆ†ç‰‡ {i+1} åˆ° {filename}")
        
        # åˆå¹¶æ‰€æœ‰åˆ†ç‰‡
        if len(self.audio_chunks) > 1:
            combined_filename = "audio_debug/combined.wav"
            combined_data = b"".join(self.audio_chunks)
            with wave.open(combined_filename, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                wf.writeframes(combined_data)
            print(f"ğŸ’¾ åˆå¹¶éŸ³é¢‘ä¿å­˜åˆ° {combined_filename}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ”§ TTSéŸ³é¢‘è°ƒè¯•å·¥å…·")
    
    try:
        # åˆå§‹åŒ–TTSæ¨¡å—
        tts_module = GenieTTSModule()
        
        # åˆ›å»ºè°ƒè¯•å™¨
        debugger = AudioDebugger(tts_module)
        
        # æµ‹è¯•æ–‡æœ¬
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯TTSæµå¼è¾“å‡ºæ˜¯å¦æ­£å¸¸ã€‚æˆ‘ä»¬å°†æ£€æŸ¥éŸ³é¢‘åˆ†ç‰‡æ˜¯å¦å®Œæ•´ï¼Œä»¥åŠæ˜¯å¦æ‰€æœ‰åˆ†ç‰‡éƒ½èƒ½æ­£ç¡®æ’­æ”¾ã€‚å¦‚æœå‘ç°é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦è°ƒè¯•ç›¸å…³ä»£ç ã€‚"
        
        # è¿è¡Œæµ‹è¯•
        num_chunks = debugger.test_tts_streaming(test_text)
        
        print(f"\nğŸ‰ è°ƒè¯•å®Œæˆï¼Œå…±ç”Ÿæˆ {num_chunks} ä¸ªéŸ³é¢‘åˆ†ç‰‡")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()