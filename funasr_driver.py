import abc
import threading
import queue
import os
import re
import time
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

import soundfile
import numpy as np
from funasr import AutoModel

# å¤ç”¨åŸºç¡€æ¥å£å®šä¹‰
@dataclass
class AudioData:
    pcm_data: bytes  
    sample_rate: int = 16000  
    channels: int = 1  
    is_finish: bool = False  # è¡¥å……is_finishå­—æ®µï¼Œå¯¹é½å…¶ä»–æ¨¡å—

@dataclass
class TextData:
    text: str  
    is_finish: bool = True  

ChatHistory = List[Dict[str, str]]  

class BaseModule(abc.ABC):
    @abc.abstractmethod
    def process(self, input_data) -> Any:
        pass

    @abc.abstractmethod
    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        pass

# FunASRæµå¼è¯†åˆ«é©±åŠ¨ï¼ˆé›†æˆæ ‡ç‚¹æ¢å¤ï¼‰
class FunASRStreamingASR(BaseModule):
    def __init__(self):
        # ========== 1. åˆå§‹åŒ–ASRæ¨¡å‹ï¼ˆåŸæœ‰é€»è¾‘ï¼‰ ==========
        self.chunk_size = [0, 10, 5]  # 600ms chunk
        self.encoder_chunk_look_back = 4
        self.decoder_chunk_look_back = 1
        self.asr_model = AutoModel(
            model="paraformer-zh-streaming", 
            model_revision="v2.0.4",
            disable_update=True  # ç¦ç”¨ç‰ˆæœ¬æ›´æ–°æ£€æŸ¥
        )
        self.chunk_stride = self.chunk_size[1] * 960  # 600ms stride
        
        # ========== 2. åˆå§‹åŒ–æ ‡ç‚¹æ¢å¤æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼‰ ==========
        self.use_punc_model = False
        self.punc_model = None
        
        # æœ¬åœ°æ ‡ç‚¹æ¨¡å‹è·¯å¾„
        local_punc_model_path = r"C:\Users\k\.cache\modelscope\hub\iic\punc_ct-transformer_cn-en-common-vocab471067-large"
        
        # ä¼˜å…ˆå°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
        if os.path.exists(local_punc_model_path):
            try:
                print(f"ğŸ”„ å°è¯•åŠ è½½æœ¬åœ°æ ‡ç‚¹æ¨¡å‹: {local_punc_model_path}")
                
                # æ–¹æ³•1ï¼šå°è¯•é€šè¿‡æœ¬åœ°è·¯å¾„åŠ è½½
                try:
                    self.punc_model = AutoModel(
                        model=local_punc_model_path,
                        disable_update=True
                    )
                    self.use_punc_model = True
                    print(f"âœ… æœ¬åœ°æ ‡ç‚¹æ¢å¤æ¨¡å‹åŠ è½½æˆåŠŸ: {local_punc_model_path}")
                except Exception as e1:
                    print(f"âš ï¸  é€šè¿‡æœ¬åœ°è·¯å¾„åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹å¼: {e1}")
                    
                    # æ–¹æ³•2ï¼šå°è¯•ä½¿ç”¨æ¨¡å‹åç§°åŠ è½½ï¼ˆå¯èƒ½å·²ç¼“å­˜ï¼‰
                    self.punc_model = AutoModel(
                        model="iic/punc_ct-transformer_cn-en-common-vocab471067-large",
                        model_revision="v2.0.4",
                        disable_update=True
                    )
                    self.use_punc_model = True
                    print(f"âœ… é€šè¿‡æ¨¡å‹åç§°åŠ è½½æ ‡ç‚¹æ¨¡å‹æˆåŠŸ")
                    
            except Exception as e:
                print(f"âŒ æ ‡ç‚¹æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.use_punc_model = False
        else:
            print(f"âš ï¸  æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {local_punc_model_path}")
            
            # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯•åŠ è½½å…¬å¼€æ¨¡å‹
            print("ğŸ”„ å°è¯•åŠ è½½å…¬å¼€æ ‡ç‚¹æ¨¡å‹...")
            punc_model_candidates = [
                "ct-punc",
                "punc_ct-transformer_zh-cn-common-vocab272727",
                "punc_ct-transformer_cn",
            ]
            
            for model_name in punc_model_candidates:
                try:
                    print(f"ğŸ”„ å°è¯•åŠ è½½æ ‡ç‚¹æ¨¡å‹: {model_name}")
                    self.punc_model = AutoModel(
                        model=model_name,
                        model_revision="v1.0.2",
                        disable_update=True
                    )
                    self.use_punc_model = True
                    print(f"âœ… æ ‡ç‚¹æ¢å¤æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
                    break
                except Exception as e:
                    print(f"âš ï¸  æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}")
                    continue
        
        if not self.use_punc_model:
            print("âš ï¸  æ‰€æœ‰æ ‡ç‚¹æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé™çº§ä¸ºæ™ºèƒ½è§„åˆ™æ ‡ç‚¹")
        else:
            print("âœ… æ ‡ç‚¹æ¢å¤æ¨¡å—å·²å°±ç»ª")
        
        # ========== 3. æµå¼ç¼“å­˜ ==========
        self.cache = {}  # ASRæµå¼ç¼“å­˜
        self.punc_buffer = ""  # æ ‡ç‚¹æ¢å¤ç”¨æ–‡æœ¬ç¼“å­˜
        self.vad_active = False  # ç®€æ˜“VADçŠ¶æ€æ ‡è®°
        self.last_speech_time = time.time()
        self.silence_threshold = 1.0  # é™éŸ³é˜ˆå€¼ï¼ˆç§’ï¼‰

    def _audio_data_to_numpy(self, audio_data: AudioData) -> np.ndarray:
        """æ ¼å¼è½¬æ¢ï¼šAudioData â†’ numpy float32æ•°ç»„ï¼ˆé€‚é…FunASRï¼‰"""
        if audio_data.sample_rate != 16000:
            raise ValueError(f"ä»…æ”¯æŒ16000Hzé‡‡æ ·ç‡ï¼Œå½“å‰ä¸º{audio_data.sample_rate}Hz")
        if audio_data.channels != 1:
            raise ValueError(f"ä»…æ”¯æŒå•å£°é“ï¼Œå½“å‰ä¸º{audio_data.channels}å£°é“")
        
        speech = np.frombuffer(audio_data.pcm_data, dtype=np.int16)
        speech = speech.astype(np.float32) / 32767.0
        return speech

    def _simple_vad(self, speech_chunk: np.ndarray) -> bool:
        """ç®€æ˜“VADï¼šé€šè¿‡éŸ³é¢‘èƒ½é‡åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ•ˆè¯­éŸ³"""
        if len(speech_chunk) == 0:
            return False
        
        rms = np.sqrt(np.mean(np.square(speech_chunk)))
        return rms > 0.005  # å¯æ ¹æ®ç¯å¢ƒè°ƒæ•´é˜ˆå€¼

    def _add_punctuation(self, text: str, is_final: bool = False) -> str:
        """
        æ ¸å¿ƒï¼šæ ‡ç‚¹æ¢å¤é€»è¾‘ï¼ˆæ¨¡å‹ä¼˜å…ˆï¼Œè§„åˆ™é™çº§ï¼‰
        :param text: æ— æ ‡ç‚¹æ–‡æœ¬
        :param is_final: æ˜¯å¦æ˜¯æœ€åä¸€ä¸ªåˆ†ç‰‡ï¼ˆå†³å®šæ˜¯å¦æ¸…ç©ºç¼“å­˜ï¼‰
        :return: å¸¦æ ‡ç‚¹æ–‡æœ¬
        """
        if not text.strip():
            return ""
        
        # æ­¥éª¤1ï¼šæ›´æ–°æ ‡ç‚¹ç¼“å­˜ï¼ˆæµå¼æ‹¼æ¥ï¼‰
        self.punc_buffer += text
        
        # æ­¥éª¤2ï¼šä»…åœ¨ã€Œæœ‰æœ‰æ•ˆæ–‡æœ¬+ï¼ˆæœ€ååˆ†ç‰‡/ç¼“å­˜è¶³å¤Ÿé•¿ï¼‰ã€æ—¶åšæ ‡ç‚¹æ¢å¤
        if len(self.punc_buffer) < 2 and not is_final:
            return self.punc_buffer  # æ–‡æœ¬è¿‡çŸ­æ—¶æš‚ä¸å¤„ç†
        
        try:
            # æ–¹æ¡ˆAï¼šä½¿ç”¨æ ‡ç‚¹æ¨¡å‹ï¼ˆä¼˜å…ˆï¼‰
            if self.use_punc_model and self.punc_model is not None:
                # è°ƒç”¨æ ‡ç‚¹æ¨¡å‹
                ##print(f"ğŸ”¤ æ ‡ç‚¹æ¨¡å‹è¾“å…¥: {self.punc_buffer}")
                punc_result = self.punc_model.generate(input=self.punc_buffer)
                ##print(f"ğŸ”¤ æ ‡ç‚¹æ¨¡å‹åŸå§‹è¾“å‡º: {punc_result}")
                
                # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
                punctuated_text = self._extract_text_from_punc_result(punc_result)
                    
                # æ¸…ç†ç»“æœ
                punctuated_text = punctuated_text.strip()
                
            # æ–¹æ¡ˆBï¼šæ™ºèƒ½è§„åˆ™æ ‡ç‚¹ï¼ˆé™çº§ï¼‰
            else:
                punctuated_text = self._smart_rule_based_punc(self.punc_buffer)
        
        except Exception as e:
            print(f"âš ï¸  æ ‡ç‚¹æ¢å¤å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æœ¬ï¼š{e}")
            import traceback
            traceback.print_exc()
            punctuated_text = self.punc_buffer
        
        # æ­¥éª¤3ï¼šæœ€ååˆ†ç‰‡æ—¶æ¸…ç©ºç¼“å­˜ï¼Œå¦åˆ™ä¿ç•™æœ«å°¾å­—ç¬¦ï¼ˆé¿å…æ–­å¥ï¼‰
        if is_final:
            final_text = punctuated_text
            self.punc_buffer = ""  # æ¸…ç©ºç¼“å­˜
            ##print(f"âœ… æœ€ç»ˆæ ‡ç‚¹ç»“æœ: {final_text}")
        else:
            # ä¿ç•™æœ€å1-2ä¸ªå­—ç¬¦ï¼Œé¿å…æ–­å¥ï¼ˆå¦‚"ä»Šå¤©å¤©æ°”"â†’ ä¿ç•™"å¤©æ°”"ï¼‰
            final_text = punctuated_text[:-2] if len(punctuated_text) > 2 else ""
            self.punc_buffer = punctuated_text[-2:] if len(punctuated_text) > 2 else punctuated_text
            ##print(f"ğŸ“ ä¸´æ—¶æ ‡ç‚¹ç»“æœ: {final_text}")
        
        return final_text.strip()

    def _extract_text_from_punc_result(self, punc_result) -> str:
        """ä»æ ‡ç‚¹æ¨¡å‹ç»“æœä¸­æå–æ–‡æœ¬"""
        if punc_result is None:
            return self.punc_buffer
            
        # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
        if isinstance(punc_result, list):
            if len(punc_result) > 0:
                if isinstance(punc_result[0], dict):
                    # æ ¼å¼: [{'text': 'å¸¦æ ‡ç‚¹çš„æ–‡æœ¬'}]
                    return punc_result[0].get("text", self.punc_buffer)
                elif isinstance(punc_result[0], str):
                    # æ ¼å¼: ['å¸¦æ ‡ç‚¹çš„æ–‡æœ¬']
                    return punc_result[0]
                else:
                    # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    return str(punc_result[0])
            else:
                return self.punc_buffer
        elif isinstance(punc_result, dict):
            # æ ¼å¼: {'text': 'å¸¦æ ‡ç‚¹çš„æ–‡æœ¬'}
            return punc_result.get("text", self.punc_buffer)
        elif isinstance(punc_result, str):
            # æ ¼å¼: 'å¸¦æ ‡ç‚¹çš„æ–‡æœ¬'
            return punc_result
        else:
            # å…¶ä»–æ ¼å¼ï¼Œå°è¯•è½¬æ¢
            return str(punc_result) if punc_result else self.punc_buffer

    def _smart_rule_based_punc(self, text: str) -> str:
        """æ™ºèƒ½è§„åˆ™æ ‡ç‚¹æ¢å¤ï¼ˆæ¨¡å‹é™çº§æ—¶ä½¿ç”¨ï¼‰"""
        if not text.strip():
            return ""
        
        # æ¸…ç†æ–‡æœ¬ï¼šå»é™¤å¤šä½™çš„æ ‡ç‚¹
        import re
        
        # ç§»é™¤å•ç‹¬å‡ºç°çš„æ ‡ç‚¹
        text = re.sub(r'(?<!\w)[ã€‚ï¼ï¼Ÿï¼›ï¼šï¼Œã€\.!?;:,](?!\w)', '', text)
        
        # ç§»é™¤è¿ç»­é‡å¤çš„æ ‡ç‚¹
        text = re.sub(r'[ã€‚]{2,}', '', text)
        text = re.sub(r'[ï¼]{2,}', '', text)
        text = re.sub(r'[ï¼Ÿ]{2,}', '', text)
        text = re.sub(r'[\.]{2,}', '', text)
        text = re.sub(r'[!]{2,}', '', text)
        text = re.sub(r'[?]{2,}', '', text)
        
        # åˆ¤æ–­å¥å­ç±»å‹å¹¶æ·»åŠ åˆé€‚çš„æ ‡ç‚¹
        if len(text) < 3:
            return text  # çŸ­æ–‡æœ¬ä¸åŠ æ ‡ç‚¹
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å®Œæ•´å¥å­ï¼ˆå·²æœ‰æ ‡ç‚¹ï¼‰
        if re.search(r'[ã€‚ï¼ï¼Ÿ\.!?]$', text):
            return text
        
        # ç–‘é—®è¯åˆ—è¡¨
        question_words = ['å—', 'å‘¢', 'å§', 'å•Š', 'ä»€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 
                         'è°', 'å“ª', 'å“ªé‡Œ', 'å¤šå°‘', 'å‡ ', 'æ€æ ·', 'ä¸ºä½•']
        
        # æ„Ÿå¹è¯åˆ—è¡¨
        exclamation_words = ['å•Š', 'å‘€', 'å“‡', 'å“¦', 'å”‰', 'å“ˆ', 'å˜¿', 'å–‚']
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç–‘é—®è¯
        has_question = any(word in text for word in question_words)
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ„Ÿå¹è¯
        has_exclamation = any(word in text for word in exclamation_words)
        
        # æ£€æŸ¥æ˜¯å¦ä»¥ç–‘é—®è¯ç»“å°¾
        ends_with_question = text.endswith(tuple(question_words))
        
        if has_question or ends_with_question:
            # ç–‘é—®å¥åŠ é—®å·
            return text + 'ï¼Ÿ'
        elif has_exclamation:
            # æ„Ÿå¹å¥åŠ æ„Ÿå¹å·
            return text + 'ï¼'
        else:
            # é™ˆè¿°å¥åŠ å¥å·ï¼ˆä½†åªåœ¨å¥å­è¾ƒé•¿æ—¶ï¼‰
            if len(text) > 6:
                return text + 'ã€‚'
            else:
                return text

    def _numpy_to_text_data(self, asr_result: str, is_finish: bool) -> TextData:
        """æ ¼å¼è½¬æ¢ï¼šè¯†åˆ«ç»“æœ â†’ TextData"""
        return TextData(
            text=asr_result,
            is_finish=is_finish
        )

    def process(self, input_data: AudioData) -> TextData:
        """æ‰¹é‡å¤„ç†ï¼šå®Œæ•´éŸ³é¢‘è¯†åˆ«+æ ‡ç‚¹æ¢å¤"""
        # 1. éŸ³é¢‘æ ¼å¼è½¬æ¢
        speech = self._audio_data_to_numpy(input_data)
        total_chunk_num = int((len(speech)-1)/self.chunk_stride + 1)
        final_text = ""
        cache = {}

        # 2. é€chunkè¯†åˆ«
        for i in range(total_chunk_num):
            speech_chunk = speech[i*self.chunk_stride:(i+1)*self.chunk_stride]
            is_final = i == total_chunk_num - 1
            
            # 3. æµå¼ASRè¯†åˆ«
            res = self.asr_model.generate(
                input=speech_chunk,
                cache=cache,
                is_final=is_final,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=self.encoder_chunk_look_back,
                decoder_chunk_look_back=self.decoder_chunk_look_back
            )
            
            # 4. æå–è¯†åˆ«æ–‡æœ¬
            chunk_text = res[0]["text"] if res and len(res) > 0 else ""
            final_text += chunk_text

        # 5. å…¨å±€æ ‡ç‚¹æ¢å¤
        final_text = self._add_punctuation(final_text, is_final=True)
        return self._numpy_to_text_data(final_text, is_finish=True)

    # åœ¨ FunASRStreamingASR ç±»çš„ stream_process æ–¹æ³•ä¸­ä¿®æ”¹ï¼š
    def stream_process(self, input_queue: queue.Queue, output_queue: queue.Queue):
        """æµå¼å¤„ç†ï¼šéŸ³é¢‘åˆ†ç‰‡è¯†åˆ«+å®æ—¶æ ‡ç‚¹æ¢å¤"""
        # é‡ç½®æ‰€æœ‰ç¼“å­˜
        self.cache = {}
        self.punc_buffer = ""  # å­˜å‚¨æœªåŠ æ ‡ç‚¹çš„åŸå§‹æ–‡æœ¬
        self.vad_active = False
        self.last_speech_time = time.time()
        
        # æ–°å¢ï¼šå®Œæ•´å¥å­ç¼“å­˜ï¼ˆç”¨äºæ ‡ç‚¹æ¢å¤ï¼‰
        self.sentence_buffer = ""
        self.sentence_complete = False

        try:
            while True:
                # 1. ä»é˜Ÿåˆ—è·å–éŸ³é¢‘åˆ†ç‰‡
                try:
                    audio_chunk: AudioData = input_queue.get(timeout=1.0)
                except queue.Empty:
                    # æ£€æŸ¥é™éŸ³è¶…æ—¶ - ç®€åŒ–é€»è¾‘
                    if (time.time() - self.last_speech_time > self.silence_threshold and 
                        self.sentence_buffer):
                        # é™éŸ³è¶…æ—¶ï¼Œå¤„ç†ç¼“å­˜çš„å¥å­
                        final_text = self._process_sentence(self.sentence_buffer, is_final=True)
                        if final_text:
                            output_queue.put(self._numpy_to_text_data(final_text, is_finish=True))
                        self.sentence_buffer = ""
                    continue
                
                # ç»“æŸæ ‡è®°
                if audio_chunk.pcm_data == b"" and audio_chunk.is_finish:
                    # å¤„ç†æœ€åç¼“å­˜çš„æ–‡æœ¬
                    if self.sentence_buffer:
                        final_text = self._process_sentence(self.sentence_buffer, is_final=True)
                        output_queue.put(self._numpy_to_text_data(final_text, is_finish=True))
                    # æ¨é€ç»“æŸæ ‡è®°
                    output_queue.put(self._numpy_to_text_data("", is_finish=True))
                    ##print("ğŸ”¤ ASRå¤„ç†å®Œæˆ")
                    break

                # 2. æ ¼å¼è½¬æ¢
                speech_chunk = self._audio_data_to_numpy(audio_chunk)
                
                # 3. ç®€æ˜“VADè¿‡æ»¤é™éŸ³
                is_speech = self._simple_vad(speech_chunk)
                current_time = time.time()
                
                if is_speech:
                    self.last_speech_time = current_time
                    self.vad_active = True
                    
                    # 4. æµå¼ASRè¯†åˆ«
                    res = self.asr_model.generate(
                        input=speech_chunk,
                        cache=self.cache,
                        is_final=False,
                        chunk_size=self.chunk_size,
                        encoder_chunk_look_back=self.encoder_chunk_look_back,
                        decoder_chunk_look_back=self.decoder_chunk_look_back
                    )
                    
                    # 5. æå–è¯†åˆ«æ–‡æœ¬
                    chunk_text = res[0]["text"] if res and len(res) > 0 else ""
                    
                    if chunk_text:
                        print(f"ğŸ”¤ ASRè¯†åˆ«: {chunk_text}")
                        
                        # 6. ç´¯ç§¯åˆ°å¥å­ç¼“å­˜
                        self.sentence_buffer += chunk_text
                        
                        # 7. æ£€æŸ¥å¥å­æ˜¯å¦è‡ªç„¶ç»“æŸï¼ˆä¸­æ–‡å¸¸è§ç»“æŸè¯ï¼‰
                        # å¦‚æœå¥å­è¾ƒé•¿ä¸”æœ‰æ˜æ˜¾çš„ç»“æŸè¯ï¼Œå¯ä»¥æå‰å¤„ç†
                        if len(self.sentence_buffer) >= 8:  # å¥å­è¾ƒé•¿æ—¶
                            # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªç„¶ç»“æŸè¯
                            end_words = ['å—', 'å‘¢', 'å§', 'å•Š', 'å‘€', 'å“¦', 'å“ˆ', 'å•¦', 'çš„', 'äº†']
                            if any(self.sentence_buffer.endswith(word) for word in end_words):
                                # æå‰å¤„ç†å¥å­
                                final_text = self._process_sentence(self.sentence_buffer, is_final=False)
                                if final_text:
                                    # åªè¾“å‡ºå·²ç»å®Œæˆçš„å¥å­éƒ¨åˆ†
                                    output_queue.put(self._numpy_to_text_data(final_text, is_finish=False))
                                    # æ¸…ç©ºç¼“å­˜ï¼Œä½†ä¿ç•™æœ€åå‡ ä¸ªå­—ç¬¦ä»¥é˜²æ–­å¥
                                    self.sentence_buffer = self.sentence_buffer[-3:] if len(self.sentence_buffer) > 3 else ""
                        
                elif self.vad_active and not is_speech:
                    # VADä»æ¿€æ´»å˜é™éŸ³ï¼Œå¤„ç†å®Œæ•´å¥å­
                    silence_duration = current_time - self.last_speech_time
                    if silence_duration > 0.5 and self.sentence_buffer:  # 0.5ç§’é™éŸ³
                        # å¤„ç†ç¼“å­˜çš„å¥å­
                        final_text = self._process_sentence(self.sentence_buffer, is_final=True)
                        if final_text:
                            output_queue.put(self._numpy_to_text_data(final_text, is_finish=True))
                        self.sentence_buffer = ""
                        self.vad_active = False

        except Exception as e:
            print(f"âŒ ASRæµå¼å¤„ç†å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            output_queue.put(self._numpy_to_text_data("", is_finish=True))

    def _process_sentence(self, text: str, is_final: bool = False) -> str:
        """å¤„ç†å¥å­ï¼šæ·»åŠ æ ‡ç‚¹"""
        if not text.strip():
            return ""
        
        # ç§»é™¤å¯èƒ½çš„é‡å¤æ–‡æœ¬ï¼ˆç®€å•å»é‡ï¼‰
        # å¦‚æœæ–‡æœ¬ä»¥æ ‡ç‚¹ç»“å°¾ï¼Œå¯èƒ½æ˜¯ä¸Šæ¬¡æ®‹ç•™çš„
        import re
        text = text.strip()
        
        # å¤„ç†é‡å¤æ–‡æœ¬ï¼ˆå¦‚"èµ¢ï¼Ÿèµ¢ï¼Ÿ" -> "èµ¢ï¼Ÿ"ï¼‰
        if len(text) >= 4 and text[-2:] == text[-4:-2]:
            # å‘ç°é‡å¤ï¼Œç§»é™¤ååŠéƒ¨åˆ†
            half_len = len(text) // 2
            if text[:half_len] == text[half_len:]:
                text = text[:half_len]
        
        ##print(f"ğŸ“ å¤„ç†å¥å­: '{text}' (is_final: {is_final})")
        
        try:
            if self.use_punc_model and self.punc_model is not None:
                ##print(f"ğŸ”¤ è°ƒç”¨æ ‡ç‚¹æ¨¡å‹: '{text}'")
                punc_result = self.punc_model.generate(input=text)
                ##print(f"ğŸ”¤ æ ‡ç‚¹æ¨¡å‹è¾“å‡º: {punc_result}")
                
                punctuated_text = self._extract_text_from_punc_result(punc_result)
                punctuated_text = punctuated_text.strip()
                
                # æ¸…ç†æ ‡ç‚¹ï¼šç§»é™¤è¿ç»­çš„æ ‡ç‚¹
                punctuated_text = re.sub(r'([ã€‚ï¼ï¼Ÿ])\1+', r'\1', punctuated_text)
                punctuated_text = re.sub(r'([,ï¼Œ])\1+', r'\1', punctuated_text)
                
                print(f"âœ… æ ‡ç‚¹ç»“æœ: '{punctuated_text}'")
                return punctuated_text
            else:
                # ä½¿ç”¨è§„åˆ™æ ‡ç‚¹
                return self._smart_rule_based_punc(text)
                
        except Exception as e:
            print(f"âš ï¸ æ ‡ç‚¹å¤„ç†å¤±è´¥: {e}")
            return text  # è¿”å›åŸæ–‡æœ¬