#!/usr/bin/env python3
"""
ASRè¯†åˆ«å‡†ç¡®æ€§è¯Šæ–­å·¥å…·
ç”¨äºæµ‹è¯•å’Œå®šä½è¯­éŸ³è¯†åˆ«ä¸å‡†ç¡®çš„é—®é¢˜
"""
import os
import sys
import time
import queue
import threading
import numpy as np
import sounddevice as sd
import soundfile as sf
from pathlib import Path
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æ‚¨çš„ASRæ¨¡å—
try:
    from funasr_driver import FunASRStreamingASR, AudioData, TextData
    from audio_player import AudioDriver
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ä»¥ä¸‹æ¨¡å—å·²å®‰è£…:")
    print("  pip install sounddevice soundfile")
    sys.exit(1)

# ===================== æµ‹è¯•é…ç½® =====================
TEST_DURATION = 5  # å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
SAMPLE_RATE = 16000
CHUNK_DURATION = 0.6  # åˆ†ç‰‡æ—¶é•¿
TEST_PHRASES = [
    "ä»Šå¤©å¤©æ°”çœŸå¥½",
    "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
    "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½",
    "æˆ‘æƒ³å–ä¸€æ¯å’–å•¡",
    "æ˜å¤©ä¸‹åˆä¸‰ç‚¹å¼€ä¼š",
    "è¿™ä¸ªç³»ç»Ÿè¿è¡Œå¾—å¾ˆæµç•…",
    "æµ‹è¯•è¯­éŸ³è¯†åˆ«å‡†ç¡®æ€§",
    "æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹"
]

# ===================== æµ‹è¯•1ï¼šç›´æ¥å½•éŸ³å¹¶è¯†åˆ« =====================
def test_direct_recognition():
    """æµ‹è¯•1ï¼šç›´æ¥å½•éŸ³å¹¶è¯†åˆ«ï¼ˆæœ€æ¥è¿‘çœŸå®ä½¿ç”¨åœºæ™¯ï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯•1ï¼šç›´æ¥å½•éŸ³å¹¶è¯†åˆ«")
    print("="*60)
    
    # åˆå§‹åŒ–ASR
    print("ğŸ”„ åˆå§‹åŒ–ASRæ¨¡å—...")
    asr_module = FunASRStreamingASR()
    
    # æç¤ºç”¨æˆ·è¯´è¯
    print(f"ğŸ¤ è¯·å¯¹ç€éº¦å…‹é£è¯´ä¸€å¥è¯ï¼ˆ{TEST_DURATION}ç§’ï¼‰...")
    print("3ç§’åå¼€å§‹å½•éŸ³...")
    time.sleep(3)
    
    try:
        # ç›´æ¥ä½¿ç”¨sounddeviceå½•éŸ³ï¼ˆé¿å…å¤æ‚é˜Ÿåˆ—ï¼‰
        print("ğŸ”´ å¼€å§‹å½•éŸ³...")
        audio_data = sd.rec(
            int(TEST_DURATION * SAMPLE_RATE),
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.int16
        )
        sd.wait()  # ç­‰å¾…å½•éŸ³å®Œæˆ
        print("âœ… å½•éŸ³å®Œæˆ")
        
        # è½¬æ¢ä¸ºAudioDataæ ¼å¼
        pcm_bytes = audio_data.tobytes()
        audio_chunk = AudioData(
            pcm_data=pcm_bytes,
            sample_rate=SAMPLE_RATE,
            channels=1,
            is_finish=True
        )
        
        # ä¿å­˜å½•éŸ³ä»¥ä¾¿æ£€æŸ¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        wav_file = f"test_recording_{timestamp}.wav"
        sf.write(wav_file, audio_data, SAMPLE_RATE)
        print(f"ğŸ’¾ å½•éŸ³å·²ä¿å­˜: {wav_file}")
        
        # ä½¿ç”¨ASRè¯†åˆ«
        print("ğŸ”„ æ­£åœ¨è¯†åˆ«...")
        start_time = time.time()
        result = asr_module.process(audio_chunk)
        elapsed = time.time() - start_time
        
        print(f"â±ï¸  è¯†åˆ«è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result.text}")
        
        return result.text, wav_file
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•1å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None

# ===================== æµ‹è¯•2ï¼šæµå¼è¯†åˆ«æµ‹è¯• =====================
def test_streaming_recognition():
    """æµ‹è¯•2ï¼šæ¨¡æ‹Ÿæµå¼è¯†åˆ«"""
    print("\n" + "="*60)
    print("æµ‹è¯•2ï¼šæµå¼è¯†åˆ«æµ‹è¯•")
    print("="*60)
    
    # åˆå§‹åŒ–ASR
    asr_module = FunASRStreamingASR()
    
    # åˆ›å»ºé˜Ÿåˆ—
    input_queue = queue.Queue()
    output_queue = queue.Queue()
    
    # å¯åŠ¨æµå¼å¤„ç†çº¿ç¨‹
    def run_asr():
        asr_module.stream_process(input_queue, output_queue)
    
    asr_thread = threading.Thread(target=run_asr, daemon=True)
    asr_thread.start()
    
    print("ğŸ¤ è¯·å¯¹ç€éº¦å…‹é£è¯´ä¸€å¥è¯ï¼ˆ5ç§’ï¼‰...")
    print("3ç§’åå¼€å§‹å½•éŸ³...")
    time.sleep(3)
    
    try:
        print("ğŸ”´ å¼€å§‹å½•éŸ³...")
        # å½•åˆ¶éŸ³é¢‘
        audio_data = sd.rec(
            int(5 * SAMPLE_RATE),
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.int16
        )
        sd.wait()
        print("âœ… å½•éŸ³å®Œæˆ")
        
        # å°†éŸ³é¢‘åˆ†æˆå°å—æ¨¡æ‹Ÿæµå¼è¾“å…¥
        chunk_samples = int(SAMPLE_RATE * CHUNK_DURATION)
        total_samples = len(audio_data)
        
        print(f"ğŸ“Š éŸ³é¢‘æ€»é•¿åº¦: {total_samples}æ ·æœ¬ï¼Œåˆ†ç‰‡å¤§å°: {chunk_samples}æ ·æœ¬")
        
        results = []
        for i in range(0, total_samples, chunk_samples):
            chunk = audio_data[i:min(i+chunk_samples, total_samples)]
            
            # è½¬æ¢ä¸ºAudioData
            audio_chunk = AudioData(
                pcm_data=chunk.tobytes(),
                sample_rate=SAMPLE_RATE,
                channels=1,
                is_finish=(i + chunk_samples >= total_samples)
            )
            
            # æ¨é€åˆ°è¾“å…¥é˜Ÿåˆ—
            input_queue.put(audio_chunk)
            
            # è·å–è¾“å‡º
            try:
                output = output_queue.get(timeout=0.5)
                if output.text:
                    results.append(output.text)
                    print(f"ğŸ”¤ åˆ†ç‰‡è¯†åˆ«: {output.text}")
            except queue.Empty:
                pass
        
        # å‘é€ç»“æŸæ ‡è®°
        input_queue.put(AudioData(pcm_data=b"", is_finish=True))
        
        # ç­‰å¾…æœ€åçš„ç»“æœ
        time.sleep(1)
        final_result = " ".join(results)
        
        print(f"ğŸ“ æµå¼è¯†åˆ«ç»“æœ: {final_result}")
        
        return final_result
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•2å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

# ===================== æµ‹è¯•3ï¼šé¢„å½•åˆ¶éŸ³é¢‘æµ‹è¯• =====================
def test_pre_recorded_audio():
    """æµ‹è¯•3ï¼šä½¿ç”¨é¢„å½•åˆ¶éŸ³é¢‘æ–‡ä»¶æµ‹è¯•"""
    print("\n" + "="*60)
    print("æµ‹è¯•3ï¼šé¢„å½•åˆ¶éŸ³é¢‘æµ‹è¯•")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„å½•åˆ¶çš„æµ‹è¯•æ–‡ä»¶
    test_files = [
        "test_audio.wav",
        "example.wav",
        "asr_example.wav"
    ]
    
    found_files = []
    for file in test_files:
        if os.path.exists(file):
            found_files.append(file)
    
    if not found_files:
        print("âš ï¸  æœªæ‰¾åˆ°é¢„å½•åˆ¶çš„æµ‹è¯•éŸ³é¢‘æ–‡ä»¶")
        print("è¯·å°†æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆWAVæ ¼å¼ï¼Œ16kHzï¼Œå•å£°é“ï¼‰æ”¾åœ¨å½“å‰ç›®å½•")
        return None
    
    print(f"ğŸ“ æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶: {found_files}")
    
    asr_module = FunASRStreamingASR()
    
    for audio_file in found_files[:2]:  # æµ‹è¯•å‰ä¸¤ä¸ªæ–‡ä»¶
        try:
            print(f"\nğŸ” æµ‹è¯•æ–‡ä»¶: {audio_file}")
            
            # è¯»å–éŸ³é¢‘æ–‡ä»¶
            audio_data, sr = sf.read(audio_file)
            
            # è½¬æ¢æ ¼å¼
            if sr != SAMPLE_RATE:
                print(f"âš ï¸  é‡‡æ ·ç‡ä¸åŒ¹é…: {sr}Hz -> {SAMPLE_RATE}Hzï¼Œæ­£åœ¨è½¬æ¢...")
                # ç®€å•é‡é‡‡æ ·ï¼ˆå®é™…åº”è¯¥ç”¨librosaæˆ–scipyï¼‰
                ratio = SAMPLE_RATE / sr
                new_length = int(len(audio_data) * ratio)
                indices = np.linspace(0, len(audio_data)-1, new_length).astype(int)
                audio_data = audio_data[indices]
            
            # ç¡®ä¿æ˜¯å•å£°é“
            if len(audio_data.shape) > 1:
                audio_data = audio_data[:, 0]
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_data = (audio_data * 32767).astype(np.int16)
            
            # åˆ›å»ºAudioData
            audio_chunk = AudioData(
                pcm_data=audio_data.tobytes(),
                sample_rate=SAMPLE_RATE,
                channels=1,
                is_finish=True
            )
            
            # è¯†åˆ«
            print("ğŸ”„ æ­£åœ¨è¯†åˆ«...")
            start_time = time.time()
            result = asr_module.process(audio_chunk)
            elapsed = time.time() - start_time
            
            print(f"â±ï¸  è¯†åˆ«è€—æ—¶: {elapsed:.2f}ç§’")
            print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result.text}")
            
            # æ’­æ”¾éŸ³é¢‘ä¾›å¯¹æ¯”
            print("ğŸ”Š æ’­æ”¾éŸ³é¢‘...")
            sd.play(audio_data, SAMPLE_RATE)
            sd.wait()
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ {audio_file} å¤±è´¥: {e}")
            continue
    
    return "æµ‹è¯•å®Œæˆ"

# ===================== æµ‹è¯•4ï¼šä¸åŒæ¨¡å‹å¯¹æ¯” =====================
def test_different_models():
    """æµ‹è¯•4ï¼šå°è¯•ä¸åŒçš„ASRæ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯•4ï¼šä¸åŒæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    
    print("âš ï¸  è¿™ä¸ªæµ‹è¯•éœ€è¦å®‰è£…æ›´å¤šæ¨¡å‹ï¼Œå¯èƒ½è€—æ—¶è¾ƒé•¿")
    print("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ", end="")
    choice = input().strip().lower()
    
    if choice != 'y':
        print("è·³è¿‡æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
        return None
    
    models_to_test = [
        ("paraformer-zh-streaming", "v2.0.4"),
        ("paraformer-zh", "v2.0.4"),
        ("iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch", "v2.0.4"),
    ]
    
    results = {}
    
    # å…ˆå½•åˆ¶ä¸€æ®µæµ‹è¯•éŸ³é¢‘
    print("\nğŸ¤ è¯·è¯´ä¸€å¥æµ‹è¯•è¯­å¥ï¼ˆ3ç§’ï¼‰...")
    time.sleep(2)
    
    print("ğŸ”´ å¼€å§‹å½•éŸ³...")
    test_audio = sd.rec(
        int(3 * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype=np.int16
    )
    sd.wait()
    print("âœ… å½•éŸ³å®Œæˆ")
    
    # ä¿å­˜æµ‹è¯•éŸ³é¢‘
    test_pcm = test_audio.tobytes()
    test_audio_data = AudioData(
        pcm_data=test_pcm,
        sample_rate=SAMPLE_RATE,
        channels=1,
        is_finish=True
    )
    
    # æ’­æ”¾ç»™ç”¨æˆ·å¬
    print("ğŸ”Š æ’­æ”¾æ‚¨åˆšæ‰çš„å½•éŸ³...")
    sd.play(test_audio, SAMPLE_RATE)
    sd.wait()
    
    print("æ‚¨åˆšæ‰è¯´çš„æ˜¯: ", end="")
    user_input = input().strip()
    
    for model_name, model_revision in models_to_test:
        try:
            print(f"\nğŸ”„ æµ‹è¯•æ¨¡å‹: {model_name}")
            
            # åˆ›å»ºä¸´æ—¶ASRå®ä¾‹
            from funasr import AutoModel
            test_model = AutoModel(
                model=model_name,
                model_revision=model_revision,
                disable_update=True
            )
            
            # ä½¿ç”¨åŸå§‹æ–¹æ³•å¤„ç†
            speech = np.frombuffer(test_pcm, dtype=np.int16)
            speech = speech.astype(np.float32) / 32767.0
            
            chunk_size = [0, 10, 5]
            chunk_stride = chunk_size[1] * 960
            
            total_chunk_num = int((len(speech)-1)/chunk_stride + 1)
            final_text = ""
            cache = {}
            
            for i in range(total_chunk_num):
                speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]
                is_final = i == total_chunk_num - 1
                
                res = test_model.generate(
                    input=speech_chunk,
                    cache=cache,
                    is_final=is_final,
                    chunk_size=chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1
                )
                
                chunk_text = res[0]["text"] if res and len(res) > 0 else ""
                final_text += chunk_text
            
            results[model_name] = final_text
            print(f"ğŸ“ è¯†åˆ«ç»“æœ: {final_text}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_name} æµ‹è¯•å¤±è´¥: {e}")
            results[model_name] = f"ERROR: {e}"
    
    print("\n" + "="*60)
    print("æ¨¡å‹å¯¹æ¯”ç»“æœ:")
    print("="*60)
    print(f"åŸå§‹è¯­å¥: {user_input}")
    for model, result in results.items():
        print(f"{model}: {result}")
    
    return results

# ===================== æµ‹è¯•5ï¼šéŸ³é¢‘è´¨é‡æ£€æŸ¥ =====================
def test_audio_quality():
    """æµ‹è¯•5ï¼šæ£€æŸ¥éŸ³é¢‘è¾“å…¥è´¨é‡"""
    print("\n" + "="*60)
    print("æµ‹è¯•5ï¼šéŸ³é¢‘è´¨é‡æ£€æŸ¥")
    print("="*60)
    
    print("ğŸ” æ£€æŸ¥éŸ³é¢‘è®¾å¤‡...")
    try:
        devices = sd.query_devices()
        print(f"æ‰¾åˆ° {len(devices)} ä¸ªéŸ³é¢‘è®¾å¤‡")
        
        default_input = sd.default.device[0]
        default_output = sd.default.device[1]
        
        print(f"é»˜è®¤è¾“å…¥è®¾å¤‡: {default_input} - {devices[default_input]['name']}")
        print(f"é»˜è®¤è¾“å‡ºè®¾å¤‡: {default_output} - {devices[default_output]['name']}")
        
        # æ£€æŸ¥è¾“å…¥è®¾å¤‡å‚æ•°
        input_info = devices[default_input]
        print(f"è¾“å…¥è®¾å¤‡å‚æ•°:")
        print(f"  æœ€å¤§è¾“å…¥é€šé“æ•°: {input_info['max_input_channels']}")
        print(f"  é»˜è®¤é‡‡æ ·ç‡: {input_info['default_samplerate']}")
        
        # æµ‹è¯•å½•éŸ³è´¨é‡
        print("\nğŸ¤ æ­£åœ¨æµ‹è¯•å½•éŸ³è´¨é‡...")
        test_duration = 2
        
        # å½•éŸ³
        print("ğŸ”´ è¯·ä¿æŒå®‰é™2ç§’...")
        time.sleep(1)
        silence = sd.rec(
            int(test_duration * SAMPLE_RATE),
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.int16
        )
        sd.wait()
        
        # è®¡ç®—å™ªéŸ³æ°´å¹³
        silence_rms = np.sqrt(np.mean(np.square(silence.astype(np.float32) / 32767.0)))
        print(f"ğŸ“Š ç¯å¢ƒå™ªéŸ³æ°´å¹³: {silence_rms:.6f}")
        
        if silence_rms > 0.01:
            print("âš ï¸  ç¯å¢ƒå™ªéŸ³è¾ƒé«˜ï¼Œå¯èƒ½å½±å“è¯†åˆ«")
        else:
            print("âœ… ç¯å¢ƒå™ªéŸ³æ°´å¹³æ­£å¸¸")
        
        print("\nğŸ”´ è¯·è¯´ä¸€å¥è¯æµ‹è¯•...")
        time.sleep(1)
        speech = sd.rec(
            int(test_duration * SAMPLE_RATE),
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.int16
        )
        sd.wait()
        
        # è®¡ç®—è¯­éŸ³èƒ½é‡
        speech_rms = np.sqrt(np.mean(np.square(speech.astype(np.float32) / 32767.0)))
        print(f"ğŸ“Š è¯­éŸ³èƒ½é‡æ°´å¹³: {speech_rms:.6f}")
        
        if speech_rms < 0.02:
            print("âš ï¸  è¯­éŸ³ä¿¡å·è¾ƒå¼±ï¼Œå»ºè®®é è¿‘éº¦å…‹é£æˆ–æé«˜éŸ³é‡")
        else:
            print("âœ… è¯­éŸ³ä¿¡å·å¼ºåº¦æ­£å¸¸")
        
        # è®¡ç®—ä¿¡å™ªæ¯”ï¼ˆç²—ç•¥ï¼‰
        if silence_rms > 0:
            snr = 20 * np.log10(speech_rms / silence_rms) if speech_rms > 0 else 0
            print(f"ğŸ“Š ä¿¡å™ªæ¯”(SNR): {snr:.2f} dB")
            
            if snr < 10:
                print("âš ï¸  ä¿¡å™ªæ¯”è¾ƒä½ï¼Œè¯­éŸ³å¯èƒ½è¢«å™ªéŸ³å¹²æ‰°")
            else:
                print("âœ… ä¿¡å™ªæ¯”è‰¯å¥½")
        
        return {
            "noise_level": silence_rms,
            "speech_level": speech_rms,
            "snr": snr if 'snr' in locals() else 0
        }
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

# ===================== ä¸»æµ‹è¯•å‡½æ•° =====================
def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("""
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
    â•šâ•â•â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•
    ASRè¯†åˆ«å‡†ç¡®æ€§è¯Šæ–­å·¥å…·
    """)
    
    print("è¯·é€‰æ‹©æµ‹è¯•é¡¹ç›®:")
    print("1. ç›´æ¥å½•éŸ³è¯†åˆ«æµ‹è¯•")
    print("2. æµå¼è¯†åˆ«æµ‹è¯•")
    print("3. é¢„å½•åˆ¶éŸ³é¢‘æµ‹è¯•")
    print("4. ä¸åŒæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("5. éŸ³é¢‘è´¨é‡æ£€æŸ¥")
    print("6. å…¨éƒ¨æµ‹è¯•")
    print("0. é€€å‡º")
    
    try:
        choice = input("è¯·é€‰æ‹© (0-6): ").strip()
        
        if choice == '1':
            test_direct_recognition()
        elif choice == '2':
            test_streaming_recognition()
        elif choice == '3':
            test_pre_recorded_audio()
        elif choice == '4':
            test_different_models()
        elif choice == '5':
            test_audio_quality()
        elif choice == '6':
            print("\nğŸš€ å¼€å§‹å…¨éƒ¨æµ‹è¯•...")
            test_direct_recognition()
            test_streaming_recognition()
            test_pre_recorded_audio()
            test_audio_quality()
            print("\nâœ… å…¨éƒ¨æµ‹è¯•å®Œæˆ")
        elif choice == '0':
            print("é€€å‡ºæµ‹è¯•")
            return
        else:
            print("æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

# ===================== å¿«é€Ÿè¯Šæ–­å‡½æ•° =====================
def quick_diagnosis():
    """å¿«é€Ÿè¯Šæ–­ï¼šè¿è¡Œå…³é”®æµ‹è¯•"""
    print("\nğŸš€ å¿«é€Ÿè¯Šæ–­å¼€å§‹...")
    
    # 1. æ£€æŸ¥éŸ³é¢‘è´¨é‡
    print("\n[1/3] æ£€æŸ¥éŸ³é¢‘è´¨é‡...")
    quality = test_audio_quality()
    
    # 2. ç›´æ¥å½•éŸ³æµ‹è¯•
    print("\n[2/3] ç›´æ¥å½•éŸ³è¯†åˆ«æµ‹è¯•...")
    result, wav_file = test_direct_recognition()
    
    # 3. æç¤ºç”¨æˆ·å¯¹æ¯”
    print("\n" + "="*60)
    print("è¯Šæ–­å»ºè®®:")
    print("="*60)
    
    if quality:
        if quality.get("snr", 0) < 10:
            print("ğŸ”´ é—®é¢˜: ç¯å¢ƒå™ªéŸ³å¤ªé«˜")
            print("å»ºè®®: åœ¨å®‰é™ç¯å¢ƒä¸­æµ‹è¯•ï¼Œä½¿ç”¨å®šå‘éº¦å…‹é£")
        
        if quality.get("speech_level", 0) < 0.02:
            print("ğŸ”´ é—®é¢˜: è¯­éŸ³ä¿¡å·å¤ªå¼±")
            print("å»ºè®®: é è¿‘éº¦å…‹é£è¯´è¯ï¼Œæé«˜éŸ³é‡")
    
    if result:
        print(f"ğŸ“ æ‚¨çš„è¯†åˆ«ç»“æœ: {result}")
        print("è¯·å¯¹æ¯”å®é™…è¯´è¯å†…å®¹ï¼Œåˆ¤æ–­è¯†åˆ«å‡†ç¡®æ€§")
        
        if wav_file:
            print(f"ğŸ’¾ å½•éŸ³æ–‡ä»¶: {wav_file}")
            print("å¯ä»¥æ’­æ”¾æ­¤æ–‡ä»¶æ£€æŸ¥å½•éŸ³è´¨é‡")
    
    print("\nğŸ”§ ä¸‹ä¸€æ­¥:")
    print("1. å¦‚æœè¯†åˆ«å®Œå…¨é”™è¯¯ï¼šå¯èƒ½æ˜¯æ¨¡å‹é—®é¢˜ï¼Œå°è¯•æµ‹è¯•4ï¼ˆä¸åŒæ¨¡å‹ï¼‰")
    print("2. å¦‚æœéƒ¨åˆ†é”™è¯¯ï¼šå¯èƒ½æ˜¯éŸ³é¢‘è´¨é‡é—®é¢˜ï¼Œå°è¯•æ”¹å–„å½•éŸ³ç¯å¢ƒ")
    print("3. å¦‚æœå»¶è¿Ÿé«˜ï¼šå¯èƒ½æ˜¯ç¡¬ä»¶æˆ–é…ç½®é—®é¢˜")

# ===================== æ‰§è¡Œå…¥å£ =====================
if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import sounddevice
        import soundfile
        import numpy
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…: pip install sounddevice soundfile numpy")
        sys.exit(1)
    
    print("\næ¬¢è¿ä½¿ç”¨ASRè¯†åˆ«å‡†ç¡®æ€§è¯Šæ–­å·¥å…·")
    print("æœ¬å·¥å…·å°†å¸®åŠ©æ‚¨æ‰¾å‡ºè¯­éŸ³è¯†åˆ«ä¸å‡†ç¡®çš„åŸå› ")
    
    print("\nå¿«é€Ÿè¯Šæ–­æ¨¡å¼ï¼Ÿ(y/n): ", end="")
    quick = input().strip().lower()
    
    if quick == 'y':
        quick_diagnosis()
    else:
        main()
    
    print("\nğŸ‘‹ è¯Šæ–­å®Œæˆï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰å¸®åŠ©ï¼")